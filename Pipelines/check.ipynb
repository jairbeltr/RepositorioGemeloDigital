{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44300aeb-cbaa-498b-bb8f-80d0e57cfe18",
   "metadata": {},
   "source": [
    "En este bloque se carga el dataset resultante del proceso de unión (join) y se estandarizan los tipos básicos de las columnas temporales y categóricas, con el fin de garantizar una base consistente para las verificaciones posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0481d7-b126-44c9-9a9f-3a698b68297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loaded join dataset ===\n",
      "shape: (46135, 16)\n",
      "columns: ['id_anon', 'Ingreso', 'Genero', 'EdadAtencion', 'FechaRegistro', 'FechaTriage', 'ClasificacionTriage', 'MotivoConsulta', 'FechaPrimeraEvolucion', 'FechaPrimeraInterconsulta', 'FechaPrimeraEvaluacion', 'FechaEgreso', 'SalidaClinica', 'min_registro_a_triage', 'min_triage_a_eval', 'min_registro_a_eval']\n",
      "            id_anon  Ingreso     Genero  EdadAtencion       FechaRegistro  \\\n",
      "0  6124828209892124        1   Femenino            27 2023-08-17 18:15:08   \n",
      "1  9294009b87eac4f1        1  Masculino            26 2023-04-04 12:16:32   \n",
      "2  63cd4a4d6b899314        2  Masculino            26 2023-09-22 11:16:51   \n",
      "\n",
      "          FechaTriage  ClasificacionTriage  \\\n",
      "0 2023-08-17 18:31:41                    3   \n",
      "1 2023-04-04 12:21:24                    2   \n",
      "2 2023-09-22 11:20:51                    3   \n",
      "\n",
      "                                      MotivoConsulta FechaPrimeraEvolucion  \\\n",
      "0  Se realiza atención del paciente, con medidas ...   2023-08-17 20:10:06   \n",
      "1  Se realiza atención del paciente, con medidas ...   2023-04-04 12:54:59   \n",
      "2  Se realiza atención del paciente, con medidas ...   2023-09-22 14:42:39   \n",
      "\n",
      "  FechaPrimeraInterconsulta FechaPrimeraEvaluacion         FechaEgreso  \\\n",
      "0       2023-08-18 00:02:47    2023-08-17 20:10:06 2023-08-18 00:07:06   \n",
      "1       2023-04-04 12:54:59    2023-04-04 12:54:59 2023-04-04 19:14:50   \n",
      "2                       NaT    2023-09-22 14:42:39 1753-01-01 00:00:00   \n",
      "\n",
      "  SalidaClinica  min_registro_a_triage  min_triage_a_eval  min_registro_a_eval  \n",
      "0             S              16.550000          98.416667           114.966667  \n",
      "1             S               4.866667          33.583333            38.450000  \n",
      "2             N               4.000000         201.800000           205.800000  \n"
     ]
    }
   ],
   "source": [
    "# Block 1 — Load join dataset and set dtypes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PATH = r\"C:\\Users\\wilmerbelza\\Documents\\Prediction model\\mh.csv\"  # ajusta si corresponde\n",
    "dfj = pd.read_csv(PATH)\n",
    "\n",
    "# Expected datetime columns; coerce errors to NaT\n",
    "dt_cols = [\n",
    "    'FechaRegistro', 'FechaTriage', 'FechaPrimeraEvolucion',\n",
    "    'FechaPrimeraInterconsulta', 'FechaPrimeraEvaluacion', 'FechaEgreso'\n",
    "]\n",
    "for c in dt_cols:\n",
    "    if c in dfj.columns:\n",
    "        dfj[c] = pd.to_datetime(dfj[c], errors='coerce')\n",
    "\n",
    "# Categorical / string normalization\n",
    "for c in ['Genero', 'SalidaClinica', 'MotivoConsulta']:\n",
    "    if c in dfj.columns:\n",
    "        dfj[c] = dfj[c].astype(str)\n",
    "\n",
    "print(\"=== Loaded join dataset ===\")\n",
    "print(\"shape:\", dfj.shape)\n",
    "print(\"columns:\", list(dfj.columns))\n",
    "print(dfj.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94199ed8-674a-4a36-8bb0-ccfc920cda90",
   "metadata": {},
   "source": [
    "Se valida que el esquema del join coincida con la estructura esperada (presencia y orden de columnas clave). Cualquier desalineación detona un error temprano y evita continuar con un dataset inconsistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc242238-bcbb-4a74-861a-b094af0e0342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns: []\n",
      "Extra columns: []\n",
      "Schema OK. Column order normalized (expected first).\n"
     ]
    }
   ],
   "source": [
    "# Block 2 — Schema check (presence & minimal order)\n",
    "\n",
    "expected_cols = [\n",
    "    'id_anon','Ingreso','Genero','EdadAtencion',\n",
    "    'FechaRegistro','FechaTriage','ClasificacionTriage','MotivoConsulta',\n",
    "    'FechaPrimeraEvolucion','FechaPrimeraInterconsulta','FechaPrimeraEvaluacion',\n",
    "    'FechaEgreso','SalidaClinica',\n",
    "    'min_registro_a_triage','min_triage_a_eval','min_registro_a_eval'\n",
    "]\n",
    "\n",
    "missing = [c for c in expected_cols if c not in dfj.columns]\n",
    "extra = [c for c in dfj.columns if c not in expected_cols]\n",
    "\n",
    "print(\"Missing columns:\", missing)\n",
    "print(\"Extra columns:\", extra)\n",
    "assert not missing, f\"Esquema incompleto. Faltan columnas: {missing}\"\n",
    "\n",
    "# Reordenar para consistencia (no elimina extras)\n",
    "dfj = dfj[[c for c in expected_cols if c in dfj.columns] + extra]\n",
    "print(\"Schema OK. Column order normalized (expected first).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17dc8d5-27b3-41d1-8ffb-6d21aa3faf32",
   "metadata": {},
   "source": [
    "Se revisan el tamaño del dataset, los tipos de datos y un resumen descriptivo para confirmar que las variables numéricas y temporales tienen valores plausibles antes de aplicar controles específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1420c6f-50f1-424e-8b07-f688ec276aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DataFrame info ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46135 entries, 0 to 46134\n",
      "Data columns (total 16 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   id_anon                    46135 non-null  object        \n",
      " 1   Ingreso                    46135 non-null  int64         \n",
      " 2   Genero                     46135 non-null  object        \n",
      " 3   EdadAtencion               46135 non-null  int64         \n",
      " 4   FechaRegistro              46135 non-null  datetime64[ns]\n",
      " 5   FechaTriage                46135 non-null  datetime64[ns]\n",
      " 6   ClasificacionTriage        46135 non-null  int64         \n",
      " 7   MotivoConsulta             46135 non-null  object        \n",
      " 8   FechaPrimeraEvolucion      46113 non-null  datetime64[ns]\n",
      " 9   FechaPrimeraInterconsulta  23639 non-null  datetime64[ns]\n",
      " 10  FechaPrimeraEvaluacion     46135 non-null  datetime64[ns]\n",
      " 11  FechaEgreso                46135 non-null  datetime64[ns]\n",
      " 12  SalidaClinica              46135 non-null  object        \n",
      " 13  min_registro_a_triage      46135 non-null  float64       \n",
      " 14  min_triage_a_eval          46135 non-null  float64       \n",
      " 15  min_registro_a_eval        46135 non-null  float64       \n",
      "dtypes: datetime64[ns](6), float64(3), int64(3), object(4)\n",
      "memory usage: 5.6+ MB\n",
      "None\n",
      "\n",
      "=== Descriptive statistics (numeric) ===\n",
      "                         count        mean         std        min        25%  \\\n",
      "Ingreso                46135.0    9.832990   40.875132   1.000000   1.000000   \n",
      "EdadAtencion           46135.0   46.620418   19.445927  18.000000  30.000000   \n",
      "ClasificacionTriage    46135.0    2.793541    0.462925   1.000000   3.000000   \n",
      "min_registro_a_triage  46135.0   12.300046   40.603870   0.200000   4.750000   \n",
      "min_triage_a_eval      46135.0  103.447122  950.345975   0.900000  20.783333   \n",
      "min_registro_a_eval    46135.0  115.747168  951.155759   2.016667  31.416667   \n",
      "\n",
      "                             50%        75%           max  \n",
      "Ingreso                 3.000000   8.000000   2937.000000  \n",
      "EdadAtencion           43.000000  61.000000    104.000000  \n",
      "ClasificacionTriage     3.000000   3.000000      5.000000  \n",
      "min_registro_a_triage   8.166667  14.683333   2898.516667  \n",
      "min_triage_a_eval      40.383333  85.633333  53574.800000  \n",
      "min_registro_a_eval    52.800000  98.658333  53589.183333  \n",
      "\n",
      "=== Date columns (non-null counts) ===\n",
      "FechaRegistro: non-null 100.00%\n",
      "FechaTriage: non-null 100.00%\n",
      "FechaPrimeraEvaluacion: non-null 100.00%\n",
      "FechaPrimeraEvolucion: non-null 99.95%\n",
      "FechaPrimeraInterconsulta: non-null 51.24%\n",
      "FechaEgreso: non-null 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Block 3 — Quick info & describe\n",
    "\n",
    "print(\"=== DataFrame info ===\")\n",
    "print(dfj.info())\n",
    "\n",
    "print(\"\\n=== Descriptive statistics (numeric) ===\")\n",
    "print(dfj.select_dtypes(include=[np.number]).describe().T)\n",
    "\n",
    "print(\"\\n=== Date columns (non-null counts) ===\")\n",
    "for c in ['FechaRegistro','FechaTriage','FechaPrimeraEvaluacion','FechaPrimeraEvolucion','FechaPrimeraInterconsulta','FechaEgreso']:\n",
    "    if c in dfj.columns:\n",
    "        nn = dfj[c].notna().mean()*100\n",
    "        print(f\"{c}: non-null {nn:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4ea6f4-6b5a-4236-9c71-f248addad69d",
   "metadata": {},
   "source": [
    "Se evalúa la cobertura de campos temporales críticos (registro, triage y primera evaluación) y se reportan ausencias en otros campos de interés (evolución e interconsulta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e05299-2ab9-4f4d-a466-4dd3f227c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Critical nulls (%) ===\n",
      " - FechaRegistro: 0.00%\n",
      " - FechaTriage: 0.00%\n",
      " - FechaPrimeraEvaluacion: 0.00%\n",
      "\n",
      "=== Other nulls (%) ===\n",
      " - FechaPrimeraEvolucion: 0.05%\n",
      " - FechaPrimeraInterconsulta: 48.76%\n"
     ]
    }
   ],
   "source": [
    "# Block 4 — Critical nulls (%)\n",
    "\n",
    "def null_pct(s): return s.isna().mean()*100\n",
    "\n",
    "critical = ['FechaRegistro','FechaTriage','FechaPrimeraEvaluacion']\n",
    "others = ['FechaPrimeraEvolucion','FechaPrimeraInterconsulta']\n",
    "\n",
    "print(\"=== Critical nulls (%) ===\")\n",
    "for c in critical:\n",
    "    if c in dfj.columns:\n",
    "        print(f\" - {c}: {null_pct(dfj[c]):.2f}%\")\n",
    "\n",
    "print(\"\\n=== Other nulls (%) ===\")\n",
    "for c in others:\n",
    "    if c in dfj.columns:\n",
    "        print(f\" - {c}: {null_pct(dfj[c]):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1f5578-3822-4ce3-8300-cf2e0d189e49",
   "metadata": {},
   "source": [
    "Se verifica la existencia de episodios duplicados. Un episodio se define por id_anon + Ingreso. En caso de duplicidad, se listan ejemplos para diagnóstico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa1fd77-1b00-4dc1-a950-fa81a60e89c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated episodes: 0\n"
     ]
    }
   ],
   "source": [
    "# Block 5 — Episode duplicates check\n",
    "\n",
    "assert 'id_anon' in dfj.columns and 'Ingreso' in dfj.columns, \"Faltan id_anon/Ingreso\"\n",
    "dups = dfj.duplicated(subset=['id_anon','Ingreso'], keep=False)\n",
    "n_dups = dups.sum()\n",
    "print(f\"Duplicated episodes: {n_dups}\")\n",
    "\n",
    "if n_dups > 0:\n",
    "    print(dfj.loc[dups, ['id_anon','Ingreso']].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e17be6a-f778-4cf2-96e7-288d159e5bdd",
   "metadata": {},
   "source": [
    "Se exploran los rangos mínimos y máximos de las fechas relevantes y se detectan valores sentinela (por ejemplo, 1753-01-01) utilizados para representar ausencia. Esto permite distinguir entre ausencia real y datos potencialmente corruptos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5676f7cc-1db6-4f94-bb47-358abb1093c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Date ranges (min, max, non-null %) ===\n",
      "FechaRegistro: 2023-01-01 00:49:09  ->  2023-12-31 23:38:44  | non-null: 100.00%\n",
      "FechaTriage: 2023-01-01 01:01:52  ->  2023-12-31 23:44:18  | non-null: 100.00%\n",
      "FechaPrimeraEvolucion: 2023-01-01 01:09:52  ->  2024-01-13 18:08:45  | non-null: 99.95%\n",
      "FechaPrimeraInterconsulta: 2023-01-01 03:00:07  ->  2024-01-01 12:54:39  | non-null: 51.24%\n",
      "FechaPrimeraEvaluacion: 2023-01-01 01:09:52  ->  2024-01-13 18:08:45  | non-null: 100.00%\n",
      "FechaEgreso: 1753-01-01 00:00:00  ->  2024-01-29 05:14:00  | non-null: 100.00%\n",
      "Sentinel 1753-01-01 00:00:00 in FechaEgreso: 1135 rows\n"
     ]
    }
   ],
   "source": [
    "# Block 6 — Date ranges and sentinel detection\n",
    "\n",
    "def date_range(s):\n",
    "    if s.notna().any():\n",
    "        return s.min(), s.max(), s.notna().mean()*100\n",
    "    return (pd.NaT, pd.NaT, 0.0)\n",
    "\n",
    "print(\"=== Date ranges (min, max, non-null %) ===\")\n",
    "for c in ['FechaRegistro','FechaTriage','FechaPrimeraEvolucion','FechaPrimeraInterconsulta','FechaPrimeraEvaluacion','FechaEgreso']:\n",
    "    if c in dfj.columns:\n",
    "        dmin, dmax, cov = date_range(dfj[c])\n",
    "        print(f\"{c}: {dmin}  ->  {dmax}  | non-null: {cov:.2f}%\")\n",
    "\n",
    "# Sentinel check\n",
    "sentinel = pd.Timestamp('1753-01-01 00:00:00')\n",
    "for c in ['FechaEgreso','FechaPrimeraInterconsulta','FechaPrimeraEvolucion','FechaPrimeraEvaluacion']:\n",
    "    if c in dfj.columns:\n",
    "        n_sentinel = (dfj[c] == sentinel).sum()\n",
    "        if n_sentinel:\n",
    "            print(f\"Sentinel {sentinel} in {c}: {n_sentinel} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e75e4-1760-40d5-9e1d-a618ddfd3602",
   "metadata": {},
   "source": [
    "Se valida que los deltas de tiempo calculados sean coherentes y no negativos: registro→triage, triage→evaluación y registro→evaluación. Se reportan conteos y ejemplos si se encuentran anomalías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55210518-eac8-40a6-89fc-e99d30df51d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_registro_a_triage: negatives = 0\n",
      "min_triage_a_eval: negatives = 0\n",
      "min_registro_a_eval: negatives = 0\n"
     ]
    }
   ],
   "source": [
    "# Block 7 — Time deltas sanity checks (non-negative, coherence)\n",
    "\n",
    "checks = {\n",
    "    'min_registro_a_triage': ('FechaRegistro','FechaTriage'),\n",
    "    'min_triage_a_eval': ('FechaTriage','FechaPrimeraEvaluacion'),\n",
    "    'min_registro_a_eval': ('FechaRegistro','FechaPrimeraEvaluacion')\n",
    "}\n",
    "for col, (a,b) in checks.items():\n",
    "    if all(c in dfj.columns for c in [col, a, b]):\n",
    "        neg = (dfj[col] < 0).sum()\n",
    "        print(f\"{col}: negatives = {neg}\")\n",
    "        if neg:\n",
    "            bad = dfj.loc[dfj[col] < 0, [a,b,col]].head(5)\n",
    "            print(\"Examples of negative deltas:\\n\", bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3507d180-ef08-4379-973e-1dccd5817704",
   "metadata": {},
   "source": [
    "Se listan frecuencias de variables categóricas y estadísticas de edad por ClasificacionTriage. Esto ayuda a confirmar que la estructura poblacional no cambió tras el join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78bebb47-206d-40b7-a16f-f1a4e4e4a4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ClasificacionTriage distribution ===\n",
      "                     count  proportion\n",
      "ClasificacionTriage                   \n",
      "3                    35635    0.772407\n",
      "2                     9392    0.203576\n",
      "4                      657    0.014241\n",
      "1                      423    0.009169\n",
      "5                       28    0.000607\n",
      "\n",
      "=== SalidaClinica distribution ===\n",
      "SalidaClinica\n",
      "S    41777\n",
      "N     4358\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Age stats by ClasificacionTriage ===\n",
      "                     count    mean  median  min  max\n",
      "ClasificacionTriage                                 \n",
      "1                      423  53.548    54.0   18   99\n",
      "2                     9392  54.834    55.0   18  104\n",
      "3                    35635  44.522    41.0   18  102\n",
      "4                      657  38.735    37.0   18   86\n",
      "5                       28  42.893    39.0   21   86\n"
     ]
    }
   ],
   "source": [
    "# Block 8 — Key distributions\n",
    "\n",
    "if 'ClasificacionTriage' in dfj.columns:\n",
    "    print(\"=== ClasificacionTriage distribution ===\")\n",
    "    print(dfj['ClasificacionTriage'].value_counts().to_frame('count').assign(\n",
    "        proportion=lambda x: x['count']/x['count'].sum()\n",
    "    ))\n",
    "\n",
    "if 'SalidaClinica' in dfj.columns:\n",
    "    print(\"\\n=== SalidaClinica distribution ===\")\n",
    "    print(dfj['SalidaClinica'].value_counts())\n",
    "\n",
    "if {'EdadAtencion','ClasificacionTriage'}.issubset(dfj.columns):\n",
    "    g = dfj.groupby('ClasificacionTriage')['EdadAtencion']\n",
    "    out = pd.DataFrame({\n",
    "        'count': g.size(),\n",
    "        'mean': g.mean().round(3),\n",
    "        'median': g.median(),\n",
    "        'min': g.min(),\n",
    "        'max': g.max()\n",
    "    })\n",
    "    print(\"\\n=== Age stats by ClasificacionTriage ===\")\n",
    "    print(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a6163-c98f-4614-b395-fe0c48e75d53",
   "metadata": {},
   "source": [
    "Se generan tablas de contingencia para ClasificacionTriage vs SalidaClinica y, opcionalmente, por género. Este cruce es útil para detectar desbalances inesperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd7d11a6-c4c0-45bb-b81b-ebd955894689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Triage × SalidaClinica ===\n",
      "SalidaClinica           N      S    All\n",
      "ClasificacionTriage                    \n",
      "1                      55    368    423\n",
      "2                    1000   8392   9392\n",
      "3                    3041  32594  35635\n",
      "4                     243    414    657\n",
      "5                      19      9     28\n",
      "All                  4358  41777  46135\n",
      "\n",
      "=== Triage × Genero ===\n",
      "Genero               Femenino  Masculino    All\n",
      "ClasificacionTriage                            \n",
      "1                         169        254    423\n",
      "2                        4943       4449   9392\n",
      "3                       20268      15367  35635\n",
      "4                         366        291    657\n",
      "5                          12         16     28\n",
      "All                     25758      20377  46135\n"
     ]
    }
   ],
   "source": [
    "# Block 9 — Cross tabs\n",
    "\n",
    "if {'ClasificacionTriage','SalidaClinica'}.issubset(dfj.columns):\n",
    "    ct = pd.crosstab(dfj['ClasificacionTriage'], dfj['SalidaClinica'], margins=True)\n",
    "    print(\"=== Triage × SalidaClinica ===\")\n",
    "    print(ct)\n",
    "\n",
    "if {'ClasificacionTriage','Genero'}.issubset(dfj.columns):\n",
    "    cg = pd.crosstab(dfj['ClasificacionTriage'], dfj['Genero'], margins=True)\n",
    "    print(\"\\n=== Triage × Genero ===\")\n",
    "    print(cg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf68433-b9a6-49b7-9167-12fa2e5c7a29",
   "metadata": {},
   "source": [
    "Se presenta un resumen ejecutivo del control de calidad, incluyendo filas/columnas, nulos críticos, duplicados de episodios y rangos de fechas. Este resumen puede guardarse en un archivo de texto para auditoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e1eb14-c131-47c9-a21c-03a815245228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== QA SUMMARY ===\n",
      "Rows: 46135 | Cols: 16\n",
      "FechaRegistro non-null: 100.00%\n",
      "FechaTriage non-null: 100.00%\n",
      "FechaPrimeraEvaluacion non-null: 100.00%\n",
      "Duplicated episodes: 0\n",
      "FechaRegistro range: 2023-01-01 00:49:09 -> 2023-12-31 23:38:44\n",
      "FechaTriage range: 2023-01-01 01:01:52 -> 2023-12-31 23:44:18\n",
      "FechaPrimeraEvaluacion range: 2023-01-01 01:09:52 -> 2024-01-13 18:08:45\n",
      "FechaEgreso range: 1753-01-01 00:00:00 -> 2024-01-29 05:14:00\n",
      "\n",
      "Saved QA summary to: C:\\Users\\wilmerbelza\\Documents\\Prediction model\\artifacts\\qa_summary.txt\n"
     ]
    }
   ],
   "source": [
    "# Block 10 — QA summary (print and optional save)\n",
    "\n",
    "lines = []\n",
    "lines.append(f\"Rows: {len(dfj)} | Cols: {dfj.shape[1]}\")\n",
    "for c in ['FechaRegistro','FechaTriage','FechaPrimeraEvaluacion']:\n",
    "    if c in dfj.columns:\n",
    "        lines.append(f\"{c} non-null: {dfj[c].notna().mean()*100:.2f}%\")\n",
    "\n",
    "# Duplicates\n",
    "dup_count = dfj.duplicated(subset=['id_anon','Ingreso'], keep=False).sum() if {'id_anon','Ingreso'}.issubset(dfj.columns) else -1\n",
    "lines.append(f\"Duplicated episodes: {dup_count}\")\n",
    "\n",
    "# Date ranges\n",
    "def dr(s):\n",
    "    return (str(s.min()) if s.notna().any() else \"NaT\",\n",
    "            str(s.max()) if s.notna().any() else \"NaT\")\n",
    "for c in ['FechaRegistro','FechaTriage','FechaPrimeraEvaluacion','FechaEgreso']:\n",
    "    if c in dfj.columns:\n",
    "        mn, mx = dr(dfj[c])\n",
    "        lines.append(f\"{c} range: {mn} -> {mx}\")\n",
    "\n",
    "report = \"\\n\".join(lines)\n",
    "print(\"=== QA SUMMARY ===\\n\" + report)\n",
    "\n",
    "# Optional save\n",
    "OUT = r\"C:\\Users\\wilmerbelza\\Documents\\Prediction model\\artifacts\\qa_summary.txt\"\n",
    "try:\n",
    "    with open(OUT, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(report)\n",
    "    print(f\"\\nSaved QA summary to: {OUT}\")\n",
    "except Exception as e:\n",
    "    print(\"Skip saving QA summary:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
