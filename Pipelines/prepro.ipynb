{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "489b99fd-bd52-4e3e-9e3b-fb154ef60c3e",
   "metadata": {},
   "source": [
    "Este cuadernillo tiene como propósito cargar un archivo Excel que contiene múltiples hojas de datos clínicos y exportar cada hoja en un archivo CSV independiente. El procedimiento permite separar la información en tablas individuales y guardarlas en la carpeta de trabajo del proyecto. De esta manera, se asegura que cada dataset pueda ser utilizado de manera modular en los pasos posteriores del pipeline (prepro, join, check y exploration)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96394564-cb36-4ae8-be4c-38bc497c40ed",
   "metadata": {},
   "source": [
    "En este bloque se cargan las tablas originales de atención, triage, evolución e interconsultas. Se normalizan los tipos de datos y se verifican las dimensiones iniciales de cada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78d3bbd8-5a27-467c-b112-f6e34ad1635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atencion: (63303, 9)\n",
      "Triage: (57850, 10)\n",
      "Evolucion: (684984, 11)\n",
      "Interconsultas: (40999, 14)\n",
      "\n",
      "[atencion] dtypes (sample):\n",
      "NumeroDocumento          string[python]\n",
      "TipoDocumento            string[python]\n",
      "Genero                   string[python]\n",
      "EdadAtencion                      Int64\n",
      "Ingreso                           Int64\n",
      "FechaAdmision                    object\n",
      "FechaEgreso                      object\n",
      "SalidaClinica            string[python]\n",
      "FechaAnulacionIngreso            object\n",
      "dtype: object\n",
      "   NumeroDocumento TipoDocumento    Genero  EdadAtencion  Ingreso  \\\n",
      "0  01032023                  AS   Femenino            34        1   \n",
      "1  01072711799               CC   Femenino            27        1   \n",
      "2  0748972                   PA   Femenino            49        3   \n",
      "\n",
      "         FechaAdmision          FechaEgreso SalidaClinica  \\\n",
      "0  2023-03-01 01:42:50  1753-01-01 00:00:00             N   \n",
      "1  2023-08-17 18:15:08  2023-08-18 00:07:06             S   \n",
      "2  2023-06-01 04:22:24  2023-06-02 07:46:57             N   \n",
      "\n",
      "  FechaAnulacionIngreso  \n",
      "0   2023-03-02 13:46:44  \n",
      "1   1753-01-01 00:00:00  \n",
      "2   1753-01-01 00:00:00  \n",
      "\n",
      "[triage] dtypes (sample):\n",
      "NumeroDocumento        string[python]\n",
      "TipoDocumento          string[python]\n",
      "Genero                 string[python]\n",
      "EdadAtencion                    Int64\n",
      "Ingreso                         Int64\n",
      "FechaAdmision                  object\n",
      "Folio                           Int64\n",
      "FechaHoraAtencion              object\n",
      "ClasificacionTriage             Int64\n",
      "MotivoConsulta         string[python]\n",
      "dtype: object\n",
      "   NumeroDocumento TipoDocumento    Genero  EdadAtencion  Ingreso  \\\n",
      "0  1000288005                CC   Femenino            20        2   \n",
      "1  1000287423                CC   Femenino            21        1   \n",
      "2  1000287256                CC   Femenino            21        2   \n",
      "\n",
      "         FechaAdmision  Folio    FechaHoraAtencion  ClasificacionTriage  \\\n",
      "0  2023-02-16 12:11:33      1  2023-02-16 12:20:49                    3   \n",
      "1  2023-07-19 09:03:52      1  2023-07-19 09:18:58                    5   \n",
      "2  2023-08-04 17:23:31      2  2023-08-04 17:29:37                    4   \n",
      "\n",
      "                                      MotivoConsulta  \n",
      "0  Se realiza atención del paciente, con medidas ...  \n",
      "1  ingresa al servicio de urgencias paciente 17  ...  \n",
      "2  Se realiza atención del paciente, con medidas ...  \n",
      "\n",
      "[evolucion] dtypes (sample):\n",
      "NumeroDocumento      string[python]\n",
      "TipoDocumento        string[python]\n",
      "Genero               string[python]\n",
      "EdadAtencion                  Int64\n",
      "Ingreso                       Int64\n",
      "FechaAdmision                object\n",
      "Folio                         Int64\n",
      "FechaHoraAtencion            object\n",
      "FechaEvolucion               object\n",
      "HoraEvolucion                object\n",
      "dtype: object\n",
      "   NumeroDocumento TipoDocumento    Genero  EdadAtencion  Ingreso  \\\n",
      "0  01072711799               CC   Femenino            27        1   \n",
      "1  01072711799               CC   Femenino            27        1   \n",
      "2  01072711799               CC   Femenino            27        1   \n",
      "\n",
      "         FechaAdmision  Folio    FechaHoraAtencion FechaEvolucion  \\\n",
      "0  2023-08-17 18:15:08      2  2023-08-17 20:10:06     2023-08-17   \n",
      "1  2023-08-17 18:15:08      3  2023-08-17 21:45:43     2023-08-17   \n",
      "2  2023-08-17 18:15:08      4  2023-08-18 00:02:47     2023-08-18   \n",
      "\n",
      "  HoraEvolucion                                          Evolucion  \n",
      "0      20:17:24  ****** INGRESO URGENCIAS DIA *******_x000D_\\nM...  \n",
      "1      21:46:28  ******MOMENTO DE CUIDADO DE ADMINISTRACIÓN DE ...  \n",
      "2      00:05:20  FRACTURA DE FALANGE PROIMAL GRUESO ARTEJO NO D...  \n",
      "\n",
      "[interc] dtypes (sample):\n",
      "NumeroDocumento      string[python]\n",
      "TipoDocumento        string[python]\n",
      "Genero               string[python]\n",
      "EdadAtencion                  Int64\n",
      "Ingreso                       Int64\n",
      "FechaAdmision                object\n",
      "Folio                         Int64\n",
      "FechaHoraAtencion            object\n",
      "FechaHoraOrden               object\n",
      "Observacion          string[python]\n",
      "dtype: object\n",
      "   NumeroDocumento TipoDocumento     Genero  EdadAtencion  Ingreso  \\\n",
      "0  01072711799               CC    Femenino            27        1   \n",
      "1  1000002572                CC    Femenino            22        4   \n",
      "2  1000002426                CC   Masculino            26        1   \n",
      "\n",
      "         FechaAdmision  Folio    FechaHoraAtencion       FechaHoraOrden  \\\n",
      "0  2023-08-17 18:15:08      4  2023-08-18 00:02:47  2023-08-18 00:02:47   \n",
      "1  2023-01-04 09:10:34      8  2023-01-04 15:38:03  2023-01-04 15:38:03   \n",
      "2  2023-04-04 12:16:32      7  2023-04-04 16:28:08  2023-04-04 16:28:08   \n",
      "\n",
      "           Observacion Resultado       FechaRespuesta FechaCancelacion  \\\n",
      "0    AUTORIZAR E N EPS      <NA>  1753-01-01 00:00:00       1753-01-01   \n",
      "1   ESTUDIO DE SINCOPE      <NA>  1753-01-01 00:00:00       1753-01-01   \n",
      "2  CON MEDICO TRATANTE      <NA>  1753-01-01 00:00:00       1753-01-01   \n",
      "\n",
      "     Estado  \n",
      "0  Ordenado  \n",
      "1  Ordenado  \n",
      "2  Ordenado  \n"
     ]
    }
   ],
   "source": [
    "# Block 1 — Robust CSV loading (force dtypes, avoid DtypeWarning)\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "\n",
    "PATH = r\"C:\\Users\\wilmerbelza\\Documents\\Prediction model\"\n",
    "\n",
    "# Columns we prefer as string (identifiers / text)\n",
    "ID_LIKE_STR: List[str] = [\n",
    "    'NumeroDocumento', 'TipoDocumento', 'Genero', 'Estado',\n",
    "    'SalidaClinica', 'Observacion', 'Resultado', 'MotivoConsulta'\n",
    "]\n",
    "# Integer columns that may have missing values\n",
    "INT_OPTIONAL: List[str] = ['Ingreso', 'Folio', 'ClasificacionTriage', 'EdadAtencion']\n",
    "\n",
    "def build_dtype_map(csv_path: str) -> Dict[str, str]:\n",
    "    \"\"\"Inspect header and build dtype map: IDs->string, optional ints->Int64.\"\"\"\n",
    "    hdr = pd.read_csv(csv_path, nrows=0, low_memory=False)  # only header\n",
    "    cols = list(hdr.columns)\n",
    "    dtype_map: Dict[str, str] = {}\n",
    "    for c in cols:\n",
    "        if c in ID_LIKE_STR:\n",
    "            dtype_map[c] = 'string'\n",
    "        elif c in INT_OPTIONAL:\n",
    "            dtype_map[c] = 'Int64'\n",
    "    # If the first column is unnamed or mixed, force it to string\n",
    "    if len(cols) > 0 and (cols[0] == '' or cols[0].startswith('Unnamed')):\n",
    "        dtype_map[cols[0]] = 'string'\n",
    "    return dtype_map\n",
    "\n",
    "def read_csv_safe(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read CSV using stable dtypes. Retry with a lighter map if needed.\"\"\"\n",
    "    dtype_map = build_dtype_map(csv_path)\n",
    "    try:\n",
    "        return pd.read_csv(csv_path, dtype=dtype_map, low_memory=False)  # default engine (C)\n",
    "    except Exception:\n",
    "        # Retry: keep only string dtypes for known ID-like columns\n",
    "        slim_map = {k: v for k, v in dtype_map.items() if v == 'string'}\n",
    "        return pd.read_csv(csv_path, dtype=slim_map, low_memory=False)\n",
    "\n",
    "# Load raw tables\n",
    "df_atencion  = read_csv_safe(f\"{PATH}/atencion.csv\")\n",
    "df_triage    = read_csv_safe(f\"{PATH}/triage.csv\")\n",
    "df_evolucion = read_csv_safe(f\"{PATH}/evolucion.csv\")\n",
    "df_interc    = read_csv_safe(f\"{PATH}/interconsultas.csv\")\n",
    "\n",
    "print(\"Atencion:\", df_atencion.shape)\n",
    "print(\"Triage:\", df_triage.shape)\n",
    "print(\"Evolucion:\", df_evolucion.shape)\n",
    "print(\"Interconsultas:\", df_interc.shape)\n",
    "\n",
    "# Quick dtype sanity\n",
    "for name, df in {\"atencion\": df_atencion, \"triage\": df_triage, \"evolucion\": df_evolucion, \"interc\": df_interc}.items():\n",
    "    print(f\"\\n[{name}] dtypes (sample):\")\n",
    "    print(df.dtypes.head(10))\n",
    "    print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1025c3-eb68-4a0c-8de5-87a689616ce8",
   "metadata": {},
   "source": [
    "En este bloque se ajustan los nombres de columnas y se convierten los campos de fecha a formato datetime. Esto facilita las uniones posteriores y evita errores de consistencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ee0176-a8fc-4e29-a4d3-d5c38eb3464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2 — Normalize column names and dtypes\n",
    "\n",
    "def normalize_dates(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_datetime(df[c], errors='coerce')\n",
    "    return df\n",
    "\n",
    "df_atencion = normalize_dates(df_atencion, ['FechaAdmision','FechaEgreso','FechaAnulacionIngreso'])\n",
    "df_triage   = normalize_dates(df_triage,   ['FechaAdmision','FechaHoraAtencion'])\n",
    "df_evolucion = normalize_dates(df_evolucion, ['FechaAdmision','FechaHoraAtencion','FechaEvolucion'])\n",
    "df_interc    = normalize_dates(df_interc,    ['FechaAdmision','FechaHoraAtencion','FechaHoraOrden','FechaRespuesta','FechaCancelacion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec24120-1085-4668-8d9e-ec7a5c522ca4",
   "metadata": {},
   "source": [
    "En este bloque se filtran únicamente los pacientes con edad mayor o igual a 18 años, de modo que el pipeline se limite a la población adulta en coherencia con el estudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0271536-653c-4a96-8e25-408fe205af6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering adults:\n",
      "Atencion: (63303, 9)\n",
      "Triage: (57850, 10)\n",
      "Evolucion: (684984, 11)\n",
      "Interconsultas: (40999, 14)\n"
     ]
    }
   ],
   "source": [
    "# Block 3 — Filter adults only (EdadAtencion >= 18)\n",
    "\n",
    "df_atencion = df_atencion[df_atencion['EdadAtencion'] >= 18].copy()\n",
    "df_triage = df_triage[df_triage['EdadAtencion'] >= 18].copy()\n",
    "df_evolucion = df_evolucion[df_evolucion['EdadAtencion'] >= 18].copy()\n",
    "df_interc = df_interc[df_interc['EdadAtencion'] >= 18].copy()\n",
    "\n",
    "print(\"After filtering adults:\")\n",
    "print(\"Atencion:\", df_atencion.shape)\n",
    "print(\"Triage:\", df_triage.shape)\n",
    "print(\"Evolucion:\", df_evolucion.shape)\n",
    "print(\"Interconsultas:\", df_interc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7c60c-8cf5-4dc8-a5e7-12f05def52f8",
   "metadata": {},
   "source": [
    "En este bloque se revisan duplicados y valores nulos en columnas críticas, con el fin de identificar posibles problemas antes de la unión de tablas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "863b5e5f-b3db-4445-9e38-7719e2d015df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ATENCION ===\n",
      "Shape: (63303, 9)\n",
      "Nulls (%):\n",
      "NumeroDocumento    0.0\n",
      "TipoDocumento      0.0\n",
      "Genero             0.0\n",
      "EdadAtencion       0.0\n",
      "Ingreso            0.0\n",
      "dtype: float64\n",
      "Duplicated episodes: 26\n",
      "\n",
      "=== TRIAGE ===\n",
      "Shape: (57850, 10)\n",
      "Nulls (%):\n",
      "NumeroDocumento    0.0\n",
      "TipoDocumento      0.0\n",
      "Genero             0.0\n",
      "EdadAtencion       0.0\n",
      "Ingreso            0.0\n",
      "dtype: float64\n",
      "Duplicated episodes: 19\n",
      "\n",
      "=== EVOLUCION ===\n",
      "Shape: (684984, 11)\n",
      "Nulls (%):\n",
      "NumeroDocumento    0.0\n",
      "TipoDocumento      0.0\n",
      "Genero             0.0\n",
      "EdadAtencion       0.0\n",
      "Ingreso            0.0\n",
      "dtype: float64\n",
      "Duplicated episodes: 634333\n",
      "\n",
      "=== INTERCONSULTAS ===\n",
      "Shape: (40999, 14)\n",
      "Nulls (%):\n",
      "Observacion        0.653\n",
      "Resultado          0.410\n",
      "Genero             0.000\n",
      "EdadAtencion       0.000\n",
      "NumeroDocumento    0.000\n",
      "dtype: float64\n",
      "Duplicated episodes: 16923\n"
     ]
    }
   ],
   "source": [
    "# Block 4 — Initial QA checks\n",
    "\n",
    "for name, df in {\n",
    "    \"atencion\": df_atencion,\n",
    "    \"triage\": df_triage,\n",
    "    \"evolucion\": df_evolucion,\n",
    "    \"interconsultas\": df_interc\n",
    "}.items():\n",
    "    print(f\"\\n=== {name.upper()} ===\")\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Nulls (%):\")\n",
    "    print(df.isna().mean().round(3).sort_values(ascending=False).head(5))\n",
    "    dups = df.duplicated(subset=['NumeroDocumento','Ingreso']).sum() if {'NumeroDocumento','Ingreso'}.issubset(df.columns) else 0\n",
    "    print(\"Duplicated episodes:\", dups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ad5b8-83e9-4538-9280-fa11b812edbf",
   "metadata": {},
   "source": [
    "En este bloque se exportan las tablas preprocesadas (con población filtrada y fechas normalizadas) para su posterior uso en la etapa de unión (join)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ee64a5b-8c76-4eee-a3f0-c2e74ad328c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\wilmerbelza\\Documents\\Prediction model\\atencion_clean.csv\n",
      "Saved: C:\\Users\\wilmerbelza\\Documents\\Prediction model\\triage_clean.csv\n",
      "Saved: C:\\Users\\wilmerbelza\\Documents\\Prediction model\\evolucion_clean.csv\n",
      "Saved: C:\\Users\\wilmerbelza\\Documents\\Prediction model\\interconsultas_clean.csv\n",
      "\n",
      "All preprocessed tables saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Block 5 — Save cleaned datasets in main project folder\n",
    "\n",
    "import os\n",
    "\n",
    "OUT = r\"C:\\Users\\wilmerbelza\\Documents\\Prediction model\"\n",
    "os.makedirs(OUT, exist_ok=True)  # create base directory if missing\n",
    "\n",
    "def safe_to_csv(df, filename):\n",
    "    path = os.path.join(OUT, filename)\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Saved: {path}\")\n",
    "\n",
    "safe_to_csv(df_atencion,      \"atencion_clean.csv\")\n",
    "safe_to_csv(df_triage,        \"triage_clean.csv\")\n",
    "safe_to_csv(df_evolucion,     \"evolucion_clean.csv\")\n",
    "safe_to_csv(df_interc,        \"interconsultas_clean.csv\")\n",
    "\n",
    "print(\"\\nAll preprocessed tables saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
