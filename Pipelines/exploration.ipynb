{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0862d85c-61a3-42ae-b206-3190ec6f9563",
   "metadata": {},
   "source": [
    "Este cuadernillo realiza un análisis exploratorio sobre el dataset generado en el cuadernillo anterior (`join.ipynb`).  \n",
    "El flujo de trabajo inicia con la apertura del archivo `mh.csv`, que contiene un conjunto de datos limpio, unificado y anonimizado proveniente de los registros clínicos.  \n",
    "\n",
    "Además de la fase exploratoria, se plantean y ajustan algunos modelos orientados al análisis de tiempos y a la evaluación de posibles escenarios de predicción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d3d7f3-23ea-4d42-b76c-d1c002dfddcb",
   "metadata": {},
   "source": [
    "En este bloque se importan las librerías principales necesarias para el análisis y la visualización básica de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff0b1540-7449-4441-bb7f-5d9b97dd8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 1 — Imports\n",
    "# Load core libraries for data analysis and visualization\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional: friendlier display in notebook\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38b9182-6d89-4990-8b83-9dbe324416ff",
   "metadata": {},
   "source": [
    "En este bloque se abre el archivo mh.csv, generado en el cuaderno de join, y se convierten a formato de fecha las columnas que contienen información temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "650e4669-356c-4fe9-9ee7-d550d6d61b23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (46135, 16)\n",
      "Datetime columns parsed: ['FechaRegistro', 'FechaEgreso', 'FechaTriage', 'FechaPrimeraEvolucion', 'FechaPrimeraInterconsulta', 'FechaPrimeraEvaluacion']\n",
      "            id_anon  Ingreso     Genero  EdadAtencion       FechaRegistro         FechaTriage  ClasificacionTriage  \\\n",
      "0  6124828209892124        1   Femenino            27 2023-08-17 18:15:08 2023-08-17 18:31:41                    3   \n",
      "1  9294009b87eac4f1        1  Masculino            26 2023-04-04 12:16:32 2023-04-04 12:21:24                    2   \n",
      "2  63cd4a4d6b899314        2  Masculino            26 2023-09-22 11:16:51 2023-09-22 11:20:51                    3   \n",
      "3  8a3c5faefad7b7eb        3  Masculino            26 2023-09-23 11:01:40 2023-09-23 11:03:53                    3   \n",
      "4  bda4010562c40190        4   Femenino            22 2023-01-04 09:10:34 2023-01-04 09:15:22                    3   \n",
      "\n",
      "                                      MotivoConsulta FechaPrimeraEvolucion FechaPrimeraInterconsulta FechaPrimeraEvaluacion         FechaEgreso  \\\n",
      "0  Se realiza atención del paciente, con medidas ...   2023-08-17 20:10:06       2023-08-18 00:02:47    2023-08-17 20:10:06 2023-08-18 00:07:06   \n",
      "1  Se realiza atención del paciente, con medidas ...   2023-04-04 12:54:59       2023-04-04 12:54:59    2023-04-04 12:54:59 2023-04-04 19:14:50   \n",
      "2  Se realiza atención del paciente, con medidas ...   2023-09-22 14:42:39                       NaT    2023-09-22 14:42:39 1753-01-01 00:00:00   \n",
      "3  Se realiza atención del paciente, con medidas ...   2023-09-23 11:15:10       2023-09-23 11:15:10    2023-09-23 11:15:10 2023-09-23 11:55:53   \n",
      "4  Motivo de consulta “ me desmaye y convulsione ...   2023-01-04 11:09:10       2023-01-04 15:38:03    2023-01-04 11:09:10 2023-01-04 15:51:28   \n",
      "\n",
      "  SalidaClinica  min_registro_a_triage  min_triage_a_eval  min_registro_a_eval  \n",
      "0             S              16.550000          98.416667           114.966667  \n",
      "1             S               4.866667          33.583333            38.450000  \n",
      "2             N               4.000000         201.800000           205.800000  \n",
      "3             S               2.216667          11.283333            13.500000  \n",
      "4             S               4.800000         113.800000           118.600000  \n"
     ]
    }
   ],
   "source": [
    "# Block 2 — Load dataset from Join pipeline\n",
    "# Load the anonymized dataset and parse datetime columns\n",
    "\n",
    "# Path to the dataset generated in the Join notebook\n",
    "path = r\"C:\\Users\\wilmerbelza\\Documents\\Prediction model\\mh.csv\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Convert date columns to datetime\n",
    "dt_candidates = [\n",
    "    \"FechaRegistro\", \"FechaEgreso\", \"FechaTriage\",\n",
    "    \"FechaPrimeraEvolucion\", \"FechaPrimeraInterconsulta\", \"FechaPrimeraEvaluacion\"\n",
    "]\n",
    "for col in [c for c in dt_candidates if c in df.columns]:\n",
    "    df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Datetime columns parsed:\", [c for c in dt_candidates if c in df.columns])\n",
    "\n",
    "# Preview first rows\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d259020-7d9a-4151-a7bc-622a629c8e7e",
   "metadata": {},
   "source": [
    "En este bloque se muestra una síntesis del dataset, que incluye la estructura de las columnas, los tipos de datos asociados y la cantidad de valores no nulos presentes en cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c7545d0-d967-45c3-9179-a1b19e06df3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46135 entries, 0 to 46134\n",
      "Data columns (total 16 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   id_anon                    46135 non-null  object        \n",
      " 1   Ingreso                    46135 non-null  int64         \n",
      " 2   Genero                     46135 non-null  object        \n",
      " 3   EdadAtencion               46135 non-null  int64         \n",
      " 4   FechaRegistro              46135 non-null  datetime64[ns]\n",
      " 5   FechaTriage                46135 non-null  datetime64[ns]\n",
      " 6   ClasificacionTriage        46135 non-null  int64         \n",
      " 7   MotivoConsulta             46135 non-null  object        \n",
      " 8   FechaPrimeraEvolucion      46113 non-null  datetime64[ns]\n",
      " 9   FechaPrimeraInterconsulta  23639 non-null  datetime64[ns]\n",
      " 10  FechaPrimeraEvaluacion     46135 non-null  datetime64[ns]\n",
      " 11  FechaEgreso                46135 non-null  datetime64[ns]\n",
      " 12  SalidaClinica              46135 non-null  object        \n",
      " 13  min_registro_a_triage      46135 non-null  float64       \n",
      " 14  min_triage_a_eval          46135 non-null  float64       \n",
      " 15  min_registro_a_eval        46135 non-null  float64       \n",
      "dtypes: datetime64[ns](6), float64(3), int64(3), object(4)\n",
      "memory usage: 5.6+ MB\n",
      "\n",
      "=== Descriptive statistics (numeric) ===\n",
      "                             count                           mean                  min                         25%                  50%  \\\n",
      "Ingreso                    46135.0                        9.83299                  1.0                         1.0                  3.0   \n",
      "EdadAtencion               46135.0                      46.620418                 18.0                        30.0                 43.0   \n",
      "FechaRegistro                46135  2023-07-06 02:07:39.254470656  2023-01-01 00:49:09  2023-04-06 17:13:51.500000  2023-07-08 15:16:44   \n",
      "FechaTriage                  46135  2023-07-06 02:19:57.257223680  2023-01-01 01:01:52  2023-04-06 17:23:50.500000  2023-07-08 15:22:11   \n",
      "ClasificacionTriage        46135.0                       2.793541                  1.0                         3.0                  3.0   \n",
      "FechaPrimeraEvolucion        46113  2023-07-06 03:22:57.874980608  2023-01-01 01:09:52         2023-04-06 17:07:25  2023-07-08 17:17:38   \n",
      "FechaPrimeraInterconsulta    23639  2023-07-13 11:25:22.892254720  2023-01-01 03:00:07         2023-04-15 07:05:43  2023-07-21 22:56:35   \n",
      "FechaPrimeraEvaluacion       46135  2023-07-06 04:03:24.084556032  2023-01-01 01:09:52  2023-04-06 17:43:20.500000  2023-07-08 18:33:35   \n",
      "FechaEgreso                  46135  2016-11-10 19:22:50.206372608  1753-01-01 00:00:00  2023-04-01 11:37:06.500000  2023-07-07 11:22:27   \n",
      "min_registro_a_triage      46135.0                      12.300046                  0.2                        4.75             8.166667   \n",
      "min_triage_a_eval          46135.0                     103.447122                  0.9                   20.783333            40.383333   \n",
      "min_registro_a_eval        46135.0                     115.747168             2.016667                   31.416667                 52.8   \n",
      "\n",
      "                                                  75%                  max         std  \n",
      "Ingreso                                           8.0               2937.0   40.875132  \n",
      "EdadAtencion                                     61.0                104.0   19.445927  \n",
      "FechaRegistro              2023-10-04 09:58:32.500000  2023-12-31 23:38:44         NaN  \n",
      "FechaTriage                2023-10-04 10:27:09.500000  2023-12-31 23:44:18         NaN  \n",
      "ClasificacionTriage                               3.0                  5.0    0.462925  \n",
      "FechaPrimeraEvolucion             2023-10-04 10:33:48  2024-01-13 18:08:45         NaN  \n",
      "FechaPrimeraInterconsulta         2023-10-10 17:23:58  2024-01-01 12:54:39         NaN  \n",
      "FechaPrimeraEvaluacion     2023-10-04 10:37:49.500000  2024-01-13 18:08:45         NaN  \n",
      "FechaEgreso                       2023-10-04 19:10:15  2024-01-29 05:14:00         NaN  \n",
      "min_registro_a_triage                       14.683333          2898.516667    40.60387  \n",
      "min_triage_a_eval                           85.633333              53574.8  950.345975  \n",
      "min_registro_a_eval                         98.658333         53589.183333  951.155759  \n",
      "\n",
      "=== Date ranges (min/max) ===\n",
      "FechaRegistro: 2023-01-01 00:49:09 → 2023-12-31 23:38:44 (non-null 100.00%)\n",
      "FechaTriage: 2023-01-01 01:01:52 → 2023-12-31 23:44:18 (non-null 100.00%)\n",
      "FechaPrimeraEvaluacion: 2023-01-01 01:09:52 → 2024-01-13 18:08:45 (non-null 100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Block 3 — Dataset overview\n",
    "# Show basic info about columns, dtypes, and non-null counts\n",
    "\n",
    "df.info()\n",
    "\n",
    "# Quick descriptive statistics for numeric columns\n",
    "print(\"\\n=== Descriptive statistics (numeric) ===\")\n",
    "print(df.describe().T)\n",
    "\n",
    "# Quick descriptive statistics for datetime columns\n",
    "print(\"\\n=== Date ranges (min/max) ===\")\n",
    "for col in [\"FechaRegistro\",\"FechaTriage\",\"FechaPrimeraEvaluacion\"]:\n",
    "    if col in df.columns:\n",
    "        print(f\"{col}: {df[col].min()} → {df[col].max()} (non-null {df[col].notna().mean():.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b01eef-4421-4ae9-b52b-606108f20e86",
   "metadata": {},
   "source": [
    "En este bloque se analizan los intervalos de tiempo entre Registro, Triage y Evaluación. Se incluyen estadísticas descriptivas y ejemplos iniciales para comprobar la coherencia de los cálculos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94d22137-a99a-455f-bcb0-1b90bc9ea781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Time deltas (minutes) descriptive statistics ===\n",
      "                         count        mean         std       min         5%        25%        50%        75%         95%         99%           max\n",
      "min_registro_a_triage  46135.0   12.300046   40.603870  0.200000   2.133333   4.750000   8.166667  14.683333   31.450000   53.416667   2898.516667\n",
      "min_triage_a_eval      46135.0  103.447122  950.345975  0.900000   9.600000  20.783333  40.383333  85.633333  200.838333  306.711000  53574.800000\n",
      "min_registro_a_eval    46135.0  115.747168  951.155759  2.016667  16.450000  31.416667  52.800000  98.658333  215.333333  326.831667  53589.183333\n",
      "\n",
      "=== Preview of first 10 rows with time deltas ===\n",
      "         id_anon  Ingreso       FechaRegistro         FechaTriage FechaPrimeraEvaluacion  min_registro_a_triage  min_triage_a_eval  min_registro_a_eval\n",
      "6124828209892124        1 2023-08-17 18:15:08 2023-08-17 18:31:41    2023-08-17 20:10:06              16.550000          98.416667           114.966667\n",
      "9294009b87eac4f1        1 2023-04-04 12:16:32 2023-04-04 12:21:24    2023-04-04 12:54:59               4.866667          33.583333            38.450000\n",
      "63cd4a4d6b899314        2 2023-09-22 11:16:51 2023-09-22 11:20:51    2023-09-22 14:42:39               4.000000         201.800000           205.800000\n",
      "8a3c5faefad7b7eb        3 2023-09-23 11:01:40 2023-09-23 11:03:53    2023-09-23 11:15:10               2.216667          11.283333            13.500000\n",
      "bda4010562c40190        4 2023-01-04 09:10:34 2023-01-04 09:15:22    2023-01-04 11:09:10               4.800000         113.800000           118.600000\n",
      "12961e128b446ee1        4 2023-08-25 18:46:00 2023-08-25 18:57:21    2023-08-25 20:17:03              11.350000          79.700000            91.050000\n",
      "9796b471e986fbf0        4 2023-01-01 03:45:05 2023-01-01 03:55:11    2023-01-01 04:13:25              10.100000          18.233333            28.333333\n",
      "00851f0b3c3935b5        6 2023-05-25 16:43:03 2023-05-25 16:44:33    2023-05-25 20:24:45               1.500000         220.200000           221.700000\n",
      "0bc65fa35937b4fb        7 2023-10-02 14:48:09 2023-10-02 14:54:20    2023-10-02 15:26:03               6.183333          31.716667            37.900000\n",
      "1e643c5d226524f9        8 2023-10-08 13:28:11 2023-10-08 13:31:25    2023-10-08 14:36:24               3.233333          64.983333            68.216667\n"
     ]
    }
   ],
   "source": [
    "# Block 4 — Time deltas exploration\n",
    "# Explore descriptive stats and sample rows for time differences\n",
    "\n",
    "time_cols = ['min_registro_a_triage','min_triage_a_eval','min_registro_a_eval']\n",
    "\n",
    "print(\"=== Time deltas (minutes) descriptive statistics ===\")\n",
    "print(df[time_cols].describe(percentiles=[0.05,0.25,0.5,0.75,0.95,0.99]).T)\n",
    "\n",
    "# Show first 10 rows with key time columns to inspect coherence\n",
    "preview_cols = ['id_anon','Ingreso','FechaRegistro','FechaTriage','FechaPrimeraEvaluacion'] + time_cols\n",
    "print(\"\\n=== Preview of first 10 rows with time deltas ===\")\n",
    "print(df[preview_cols].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323bef2d-d940-4bc9-acf7-b06594b9dab0",
   "metadata": {},
   "source": [
    "En este bloque se analiza la distribución de la Clasificación de Triage, presentando tanto las frecuencias absolutas y relativas como la edad promedio de los pacientes en cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10fddd55-5ba4-410e-b820-a8924af95286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ClasificacionTriage distribution ===\n",
      "                     count  proportion\n",
      "ClasificacionTriage                   \n",
      "1                      423    0.009169\n",
      "2                     9392    0.203576\n",
      "3                    35635    0.772407\n",
      "4                      657    0.014241\n",
      "5                       28    0.000607\n",
      "\n",
      "=== Age statistics by ClasificacionTriage ===\n",
      "                     count       mean  median\n",
      "ClasificacionTriage                          \n",
      "1                      423  53.548463    54.0\n",
      "2                     9392  54.833901    55.0\n",
      "3                    35635  44.521734    41.0\n",
      "4                      657  38.735160    37.0\n",
      "5                       28  42.892857    39.0\n"
     ]
    }
   ],
   "source": [
    "# Block 5 — Triage classification exploration\n",
    "# Distribution of triage levels and relation with age\n",
    "\n",
    "# 1) Frequency table\n",
    "triage_counts = df['ClasificacionTriage'].value_counts(dropna=False).sort_index()\n",
    "triage_props  = df['ClasificacionTriage'].value_counts(normalize=True, dropna=False).sort_index()\n",
    "\n",
    "print(\"=== ClasificacionTriage distribution ===\")\n",
    "print(pd.DataFrame({'count': triage_counts, 'proportion': triage_props}))\n",
    "\n",
    "# 2) Average age by triage level\n",
    "if 'EdadAtencion' in df.columns:\n",
    "    age_by_triage = df.groupby('ClasificacionTriage')['EdadAtencion'].agg(['count','mean','median'])\n",
    "    print(\"\\n=== Age statistics by ClasificacionTriage ===\")\n",
    "    print(age_by_triage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af819252-bd1d-446b-b274-2b8f11fa0907",
   "metadata": {},
   "source": [
    "En este bloque se examinan los tiempos entre Registro, Triage y Evaluación de acuerdo con la Clasificación de Triage, presentando estadísticas descriptivas diferenciadas para cada nivel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31f0e98a-caa5-488d-895a-c0ee58c7e14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Time deltas by ClasificacionTriage ===\n",
      "   ClasificacionTriage  count  mean_reg_tri  median_reg_tri  mean_tri_eval  median_tri_eval  mean_reg_eval  median_reg_eval  p90_reg_eval\n",
      "0                    1    423      8.556738        5.983333      28.686446        21.683333      37.243184        30.166667     61.163333\n",
      "1                    2   9392     11.631793        7.316667      22.641030        18.850000      34.272823        29.225000     55.950000\n",
      "2                    3  35635     12.523935        8.433333      81.146308        52.450000      93.670244        64.716667    181.180000\n",
      "3                    4    657     12.121512        7.983333    2336.070497        96.533333    2348.192009       110.416667   7206.753333\n",
      "4                    5     28     12.251786       10.250000    4332.394643       834.725000    4344.646429       847.433333  11220.213333\n"
     ]
    }
   ],
   "source": [
    "# Block 6 — Time deltas by triage classification\n",
    "# Compare delays by triage level\n",
    "\n",
    "time_cols = ['min_registro_a_triage','min_triage_a_eval','min_registro_a_eval']\n",
    "\n",
    "# Group by triage and compute descriptive statistics\n",
    "time_by_triage = df.groupby('ClasificacionTriage')[time_cols].agg(['count','mean','median','quantile'])\n",
    "\n",
    "# Simplify: show count, mean, median, p90\n",
    "summary = df.groupby('ClasificacionTriage')[time_cols].agg(\n",
    "    count=('min_registro_a_eval','count'),\n",
    "    mean_reg_tri=('min_registro_a_triage','mean'),\n",
    "    median_reg_tri=('min_registro_a_triage','median'),\n",
    "    mean_tri_eval=('min_triage_a_eval','mean'),\n",
    "    median_tri_eval=('min_triage_a_eval','median'),\n",
    "    mean_reg_eval=('min_registro_a_eval','mean'),\n",
    "    median_reg_eval=('min_registro_a_eval','median'),\n",
    "    p90_reg_eval=('min_registro_a_eval', lambda s: s.quantile(0.9))\n",
    ").reset_index()\n",
    "\n",
    "print(\"=== Time deltas by ClasificacionTriage ===\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc26b3f5-73e4-49eb-8fb9-4a2c7eaaeb10",
   "metadata": {},
   "source": [
    "En este bloque se analiza la variable target, que representa si los pacientes de Triage III fueron atendidos dentro de las dos horas establecidas (1 = sí, 0 = no).\n",
    "Primero se presenta la distribución general de cumplimiento, y luego se muestra su relación con los diferentes niveles de clasificación de Triage, lo que permite identificar patrones iniciales de oportunidad en la atención."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17d681af-b72b-42f8-8331-28dba04f56e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overall target distribution (Triage III ≤2h) ===\n",
      "target\n",
      "1    28568\n",
      "0    17567\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Target (≤2h) by ClasificacionTriage ===\n",
      "target                   0      1    All\n",
      "ClasificacionTriage                     \n",
      "1                      423      0    423\n",
      "2                     9392      0   9392\n",
      "3                     7067  28568  35635\n",
      "4                      657      0    657\n",
      "5                       28      0     28\n",
      "All                  17567  28568  46135\n"
     ]
    }
   ],
   "source": [
    "# Block 7 — Ensure `target` exists and explore it\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def ensure_datetime(df, col):\n",
    "    if col in df.columns and not np.issubdtype(df[col].dtype, np.datetime64):\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# 1) If needed, compute min_triage_a_eval from datetimes\n",
    "if 'min_triage_a_eval' not in df.columns:\n",
    "    needed = {'FechaTriage', 'FechaPrimeraEvaluacion'}\n",
    "    if needed.issubset(df.columns):\n",
    "        df = ensure_datetime(df, 'FechaTriage')\n",
    "        df = ensure_datetime(df, 'FechaPrimeraEvaluacion')\n",
    "        df['min_triage_a_eval'] = (\n",
    "            (df['FechaPrimeraEvaluacion'] - df['FechaTriage'])\n",
    "            .dt.total_seconds() / 60.0\n",
    "        )\n",
    "    else:\n",
    "        raise KeyError(\n",
    "            \"No existe `target` ni puedo calcular `min_triage_a_eval`. \"\n",
    "            \"Faltan columnas: FechaTriage y/o FechaPrimeraEvaluacion.\"\n",
    "        )\n",
    "\n",
    "# 2) Create `target` if missing: Triage III and eval ≤ 120 min\n",
    "if 'target' not in df.columns:\n",
    "    if 'ClasificacionTriage' not in df.columns:\n",
    "        raise KeyError(\"Falta la columna `ClasificacionTriage` para definir el target.\")\n",
    "    df['target'] = (\n",
    "        (df['ClasificacionTriage'] == 3) &\n",
    "        (df['min_triage_a_eval'] <= 120)\n",
    "    ).astype('int8')\n",
    "\n",
    "# 3) Explore overall distribution\n",
    "print(\"=== Overall target distribution (Triage III ≤2h) ===\")\n",
    "print(df['target'].value_counts(dropna=False))\n",
    "\n",
    "# 4) Crosstab by triage level\n",
    "if 'ClasificacionTriage' in df.columns:\n",
    "    target_by_triage = pd.crosstab(df['ClasificacionTriage'], df['target'], margins=True)\n",
    "    print(\"\\n=== Target (≤2h) by ClasificacionTriage ===\")\n",
    "    print(target_by_triage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeacfbc9-6a69-4d39-abbd-83f1cb9148b3",
   "metadata": {},
   "source": [
    "En este bloque se examinan las características demográficas de los pacientes, mostrando la distribución del género y la edad promedio según el nivel de triage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d33348ca-1262-4f28-8466-101d421f0f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Gender distribution by ClasificacionTriage ===\n",
      "Genero               Femenino  Masculino    All\n",
      "ClasificacionTriage                            \n",
      "1                         169        254    423\n",
      "2                        4943       4449   9392\n",
      "3                       20268      15367  35635\n",
      "4                         366        291    657\n",
      "5                          12         16     28\n",
      "All                     25758      20377  46135\n",
      "\n",
      "=== Age statistics by ClasificacionTriage ===\n",
      "                     count       mean  median  min  max\n",
      "ClasificacionTriage                                    \n",
      "1                      423  53.548463    54.0   18   99\n",
      "2                     9392  54.833901    55.0   18  104\n",
      "3                    35635  44.521734    41.0   18  102\n",
      "4                      657  38.735160    37.0   18   86\n",
      "5                       28  42.892857    39.0   21   86\n"
     ]
    }
   ],
   "source": [
    "# Block 8 — Demographics by triage\n",
    "# Explore age and gender distribution by triage level\n",
    "\n",
    "# 1) Gender distribution by triage\n",
    "print(\"=== Gender distribution by ClasificacionTriage ===\")\n",
    "gender_by_triage = pd.crosstab(df['ClasificacionTriage'], df['Genero'], margins=True)\n",
    "print(gender_by_triage)\n",
    "\n",
    "# 2) Age statistics by triage\n",
    "if 'EdadAtencion' in df.columns:\n",
    "    print(\"\\n=== Age statistics by ClasificacionTriage ===\")\n",
    "    age_stats = df.groupby('ClasificacionTriage')['EdadAtencion'].agg(['count','mean','median','min','max'])\n",
    "    print(age_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe0d37-fdc2-452e-aec7-d99854688d36",
   "metadata": {},
   "source": [
    "En este bloque se comparan los tiempos de atención entre los episodios que cumplen el estándar (≤120 min desde Triage a Evaluación) y los que no cumplen. Se reportan conteo, medias, medianas y el percentil 90 para cada intervalo: registro→triage, triage→evaluación y registro→evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c0ae00f1-dbee-4a88-b360-faca9f6cdac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Time deltas by target (0 = no cumple, 1 = cumple Triage III ≤2h) ===\n",
      "   target  count  mean_reg_tri  median_reg_tri  mean_tri_eval  median_tri_eval  mean_reg_eval  median_reg_eval  p90_reg_eval\n",
      "0       0  17567     12.096415        7.883333     193.981803        38.300000     206.078218        53.033333        232.84\n",
      "1       1  28568     12.425263        8.350000      47.775646        40.816667      60.200908        52.750000        107.15\n"
     ]
    }
   ],
   "source": [
    "# Block 9 — Time deltas by target (Triage III ≤2h)\n",
    "# Compare delays between compliant vs non-compliant (target) patients\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Guard: ensure `target` exists (created in Block 7). If not, raise.\n",
    "if 'target' not in df.columns:\n",
    "    raise KeyError(\"Falta la columna `target`. Ejecute el Block 7 para crearla.\")\n",
    "\n",
    "time_cols = ['min_registro_a_triage', 'min_triage_a_eval', 'min_registro_a_eval']\n",
    "\n",
    "# Sanity: make sure time columns are numeric\n",
    "for c in time_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Summary by target (0 = no cumple, 1 = cumple)\n",
    "summary_simple = (\n",
    "    df.groupby('target')[time_cols]\n",
    "      .agg(\n",
    "          count=('min_registro_a_eval','count'),\n",
    "          mean_reg_tri=('min_registro_a_triage','mean'),\n",
    "          median_reg_tri=('min_registro_a_triage','median'),\n",
    "          mean_tri_eval=('min_triage_a_eval','mean'),\n",
    "          median_tri_eval=('min_triage_a_eval','median'),\n",
    "          mean_reg_eval=('min_registro_a_eval','mean'),\n",
    "          median_reg_eval=('min_registro_a_eval','median'),\n",
    "          p90_reg_eval=('min_registro_a_eval', lambda s: s.quantile(0.9))\n",
    "      )\n",
    "      .reset_index()\n",
    "      .sort_values('target')\n",
    ")\n",
    "\n",
    "print(\"=== Time deltas by target (0 = no cumple, 1 = cumple Triage III ≤2h) ===\")\n",
    "print(summary_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ca71fa-f487-4bb6-bb77-0957f2a30c71",
   "metadata": {},
   "source": [
    "En este bloque se realiza un cruce de los intervalos de tiempo por nivel de ClasificacionTriage y por el estado de cumplimiento del estándar (target): 0 = no cumple (atención > 120 min), 1 = cumple (≤ 120 min). Se reportan el conteo, las medias, las medianas y el percentil 90 de los tres intervalos clave: registro→triage, triage→evaluación y registro→evaluación. Este análisis permite identificar diferencias operativas dentro de cada nivel de triage según el cumplimiento del estándar de 2 horas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3fce86b5-f008-4797-a654-653e63dab72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Time deltas by ClasificacionTriage and target (0=no cumple, 1=cumple) ===\n",
      "   ClasificacionTriage  target  count  mean_reg_tri  median_reg_tri  mean_tri_eval  median_tri_eval  mean_reg_eval  median_reg_eval  p90_reg_eval\n",
      "0                    1       0    423      8.556738        5.983333      28.686446        21.683333      37.243184        30.166667     61.163333\n",
      "1                    2       0   9392     11.631793        7.316667      22.641030        18.850000      34.272823        29.225000     55.950000\n",
      "2                    3       0   7067     12.922815        8.883333     216.045571       167.916667     228.968386       181.233333    278.393333\n",
      "3                    3       1  28568     12.425263        8.350000      47.775646        40.816667      60.200908        52.750000    107.150000\n",
      "4                    4       0    657     12.121512        7.983333    2336.070497        96.533333    2348.192009       110.416667   7206.753333\n",
      "5                    5       0     28     12.251786       10.250000    4332.394643       834.725000    4344.646429       847.433333  11220.213333\n"
     ]
    }
   ],
   "source": [
    "# Block 10 — Time deltas by (ClasificacionTriage, target)\n",
    "# Cross analysis of delays by triage level and compliance outcome\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Guards\n",
    "if 'target' not in df.columns:\n",
    "    raise KeyError(\"Falta la columna `target`. Ejecute el Block 7 para crearla.\")\n",
    "if 'ClasificacionTriage' not in df.columns:\n",
    "    raise KeyError(\"Falta la columna `ClasificacionTriage`.\")\n",
    "\n",
    "time_cols = ['min_registro_a_triage', 'min_triage_a_eval', 'min_registro_a_eval']\n",
    "for c in time_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "summary_combo = (\n",
    "    df.groupby(['ClasificacionTriage', 'target'])[time_cols]\n",
    "      .agg(\n",
    "          count=('min_registro_a_eval', 'count'),\n",
    "          mean_reg_tri=('min_registro_a_triage', 'mean'),\n",
    "          median_reg_tri=('min_registro_a_triage', 'median'),\n",
    "          mean_tri_eval=('min_triage_a_eval', 'mean'),\n",
    "          median_tri_eval=('min_triage_a_eval', 'median'),\n",
    "          mean_reg_eval=('min_registro_a_eval', 'mean'),\n",
    "          median_reg_eval=('min_registro_a_eval', 'median'),\n",
    "          p90_reg_eval=('min_registro_a_eval', lambda s: s.quantile(0.9))\n",
    "      )\n",
    "      .reset_index()\n",
    "      .sort_values(['ClasificacionTriage', 'target'])\n",
    ")\n",
    "\n",
    "print(\"=== Time deltas by ClasificacionTriage and target (0=no cumple, 1=cumple) ===\")\n",
    "print(summary_combo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec620a-fb68-4d89-a5e4-0bc3ed15cb84",
   "metadata": {},
   "source": [
    "En este bloque se presenta un resumen compacto de las principales características del dataset ya procesado. Se incluye el tamaño total (filas y columnas), la cobertura de variables clave de evolución, interconsulta y evaluación médica, la distribución de pacientes por nivel de triage, la distribución del estado de cumplimiento del estándar de Triage III (variable target), y un resumen de los intervalos de tiempo en minutos. Este bloque sirve como cierre de la etapa exploratoria antes de proceder a la modelación predictiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79e5908d-f777-4aae-8595-3b6de42924c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL EXPLORATION SUMMARY ===\n",
      "Rows: 46,135\n",
      "Columns: 17\n",
      "\n",
      "Coverage:\n",
      " - FechaPrimeraEvolucion: 99.95%\n",
      " - FechaPrimeraInterconsulta: 51.24%\n",
      " - FechaPrimeraEvaluacion: 100.00%\n",
      "\n",
      "Triage distribution:\n",
      "ClasificacionTriage\n",
      "1      423\n",
      "2     9392\n",
      "3    35635\n",
      "4      657\n",
      "5       28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target distribution (0=no cumple, 1=cumple):\n",
      "target\n",
      "0    17567\n",
      "1    28568\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Time deltas (minutes):\n",
      "min_registro_a_triage: mean=12.3, median=8.2, p90=23.9\n",
      "min_triage_a_eval: mean=103.4, median=40.4, p90=154.9\n",
      "min_registro_a_eval: mean=115.7, median=52.8, p90=168.5\n"
     ]
    }
   ],
   "source": [
    "# Block 11 — Final exploration summary\n",
    "# Compact recap of dataset characteristics\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n=== FINAL EXPLORATION SUMMARY ===\")\n",
    "\n",
    "# Size\n",
    "print(f\"Rows: {len(df):,}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "\n",
    "# Coverage of key variables\n",
    "def cov(col):\n",
    "    return df[col].notna().mean() if col in df.columns else np.nan\n",
    "\n",
    "print(\"\\nCoverage:\")\n",
    "for col in ['FechaPrimeraEvolucion','FechaPrimeraInterconsulta','FechaPrimeraEvaluacion']:\n",
    "    if col in df.columns:\n",
    "        print(f\" - {col}: {cov(col):.2%}\")\n",
    "\n",
    "# Triage distribution\n",
    "if 'ClasificacionTriage' in df.columns:\n",
    "    triage_counts = df['ClasificacionTriage'].value_counts().sort_index()\n",
    "    print(\"\\nTriage distribution:\")\n",
    "    print(triage_counts)\n",
    "\n",
    "# Target distribution (cumplimiento ≤2h en Triage III)\n",
    "if 'target' in df.columns:\n",
    "    target_counts = df['target'].value_counts().sort_index()\n",
    "    print(\"\\nTarget distribution (0=no cumple, 1=cumple):\")\n",
    "    print(target_counts)\n",
    "\n",
    "# Time deltas summary\n",
    "if {'min_registro_a_triage','min_triage_a_eval','min_registro_a_eval'}.issubset(df.columns):\n",
    "    print(\"\\nTime deltas (minutes):\")\n",
    "    for c in ['min_registro_a_triage','min_triage_a_eval','min_registro_a_eval']:\n",
    "        s = df[c].dropna()\n",
    "        print(f\"{c}: mean={s.mean():.1f}, median={s.median():.1f}, p90={s.quantile(0.9):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e37c76-a8e9-4170-a834-9cca60e0cfe2",
   "metadata": {},
   "source": [
    "En este bloque se redefine la variable objetivo, enfocándola en el cumplimiento del estándar de Triage III: haber recibido la primera evaluación médica dentro de las 2 horas posteriores a la clasificación. La variable target se construye solo para pacientes con Clasificación de Triage 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31f6a0ee-f0df-49f5-bee5-c2c11ff6bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution (Triage III, 2h compliance):\n",
      "target\n",
      "1    0.801684\n",
      "0    0.198316\n",
      "Name: proportion, dtype: float64\n",
      "Train shape: (24944, 3)  Test shape: (10691, 3)\n",
      "Target distribution in train: target\n",
      "1    0.801676\n",
      "0    0.198324\n",
      "Name: proportion, dtype: float64\n",
      "Target distribution in test: target\n",
      "1    0.801702\n",
      "0    0.198298\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Block 12 — Define target for Triage III compliance (<=120 min)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Filtrar solo pacientes de Triage III\n",
    "df_triage3 = df[df['ClasificacionTriage'] == 3].copy()\n",
    "\n",
    "# 2) Crear variable objetivo: 1 si fue atendido en <= 120 min, 0 si no\n",
    "df_triage3['target'] = (df_triage3['min_triage_a_eval'] <= 120).astype(int)\n",
    "\n",
    "print(\"Target distribution (Triage III, 2h compliance):\")\n",
    "print(df_triage3['target'].value_counts(normalize=True))\n",
    "\n",
    "# 3) Seleccionar variables predictoras\n",
    "features = [\n",
    "    'EdadAtencion',\n",
    "    'Genero',\n",
    "    'min_registro_a_triage'\n",
    "]\n",
    "\n",
    "X = df_triage3[features]\n",
    "y = df_triage3['target']\n",
    "\n",
    "# 4) Dividir en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \" Test shape:\", X_test.shape)\n",
    "print(\"Target distribution in train:\", y_train.value_counts(normalize=True))\n",
    "print(\"Target distribution in test:\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a001c75a-0fc6-4643-bbff-10fadcccbafc",
   "metadata": {},
   "source": [
    "En este bloque se define un preprocesamiento que convierte las variables categóricas a numéricas y estandariza las numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db4057d3-1d4a-45d9-ae9e-e760e812cc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor ready. Numeric: ['EdadAtencion', 'min_registro_a_triage'] Categorical: ['Genero']\n"
     ]
    }
   ],
   "source": [
    "# Block 13 — Preprocessing (encode categorical + scale numeric)\n",
    "# Build a preprocessing pipeline for modeling\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Reuse the same features defined en el Block 12\n",
    "num_features = ['EdadAtencion', 'min_registro_a_triage']\n",
    "cat_features = ['Genero']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_features),\n",
    "        ('cat', OneHotEncoder(drop='if_binary', handle_unknown='ignore'), cat_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "print(\"Preprocessor ready. Numeric:\", num_features, \"Categorical:\", cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa294ec5-3aa1-446f-a06c-15f3476b2e88",
   "metadata": {},
   "source": [
    "En este bloque se entrena una regresión logística con balanceo de clases y un Pipeline de preprocesamiento (imputación, escalado y codificación). Además, se ajusta el umbral para mejorar el F1 de la clase 0 (no cumplió ≤2 horas) de manera robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7db808fd-9582-4ac0-b028-630294cf4a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix (LogReg balanced, thr=0.5) ===\n",
      "[[1207  913]\n",
      " [4528 4043]]\n",
      "\n",
      "=== Classification Report (LogReg balanced, thr=0.5) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.210     0.569     0.307      2120\n",
      "           1      0.816     0.472     0.598      8571\n",
      "\n",
      "    accuracy                          0.491     10691\n",
      "   macro avg      0.513     0.521     0.453     10691\n",
      "weighted avg      0.696     0.491     0.540     10691\n",
      "\n",
      "\n",
      "Best threshold for class 0 (train): 0.4526\n",
      "\n",
      "=== Confusion Matrix (LogReg balanced, tuned threshold) ===\n",
      "[[1958  162]\n",
      " [7464 1107]]\n",
      "\n",
      "=== Classification Report (LogReg balanced, tuned threshold) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.208     0.924     0.339      2120\n",
      "           1      0.872     0.129     0.225      8571\n",
      "\n",
      "    accuracy                          0.287     10691\n",
      "   macro avg      0.540     0.526     0.282     10691\n",
      "weighted avg      0.741     0.287     0.248     10691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Block 14 — Logistic Regression (balanced) + robust threshold tuning for class 0\n",
    "# Self-contained: builds its own preprocessor and handles missing values\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
    "\n",
    "# --- Rebuild features and target from Block 12 context (Triage III only) ---\n",
    "features = ['EdadAtencion', 'Genero', 'min_registro_a_triage']\n",
    "X_train = X_train[features].copy()\n",
    "X_test  = X_test[features].copy()\n",
    "y_train = y_train.astype(int)\n",
    "y_test  = y_test.astype(int)\n",
    "\n",
    "# --- Preprocessor: impute + scale numeric, impute + one-hot categorical ---\n",
    "num_features = ['EdadAtencion', 'min_registro_a_triage']\n",
    "cat_features = ['Genero']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), num_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('ohe', OneHotEncoder(drop='if_binary', handle_unknown='ignore'))\n",
    "        ]), cat_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# --- Model: class_weight balanced to combat 80/20 imbalance ---\n",
    "log_reg_pipe = Pipeline(steps=[\n",
    "    ('prep', preprocessor),\n",
    "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Fit\n",
    "log_reg_pipe.fit(X_train, y_train)\n",
    "\n",
    "# === Eval with default threshold (0.5) ===\n",
    "proba_test = log_reg_pipe.predict_proba(X_test)[:, 1]  # P(y=1: cumple ≤2h)\n",
    "y_pred_default = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "print(\"=== Confusion Matrix (LogReg balanced, thr=0.5) ===\")\n",
    "print(confusion_matrix(y_test, y_pred_default))\n",
    "print(\"\\n=== Classification Report (LogReg balanced, thr=0.5) ===\")\n",
    "print(classification_report(y_test, y_pred_default, digits=3))\n",
    "\n",
    "# === Robust threshold tuning to improve F1 for class 0 on TRAIN ===\n",
    "# We tune using p0 = 1 - p1 and y0 = 1 for class 0 labels\n",
    "proba_train = log_reg_pipe.predict_proba(X_train)[:, 1]\n",
    "p0_train = 1.0 - proba_train\n",
    "y0_train = (y_train == 0).astype(int)\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y0_train, p0_train)\n",
    "\n",
    "# precision_recall_curve returns len(thr)=len(prec)-1; compute F1 where valid\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    f1_0 = np.where((prec + rec) > 0, 2 * prec * rec / (prec + rec), 0.0)\n",
    "\n",
    "# Find best threshold index within available thresholds\n",
    "if thr.size > 0:\n",
    "    # Excluir el primer punto (umbral virtual) alineando con 'thr'\n",
    "    f1_aligned = f1_0[1:] if f1_0.size > 1 else f1_0\n",
    "    best_idx = int(np.argmax(f1_aligned)) if f1_aligned.size > 0 else 0\n",
    "    best_thr_for_class0 = thr[best_idx]\n",
    "else:\n",
    "    best_thr_for_class0 = 0.5  # fallback\n",
    "\n",
    "print(f\"\\nBest threshold for class 0 (train): {best_thr_for_class0:.4f}\")\n",
    "\n",
    "# Apply tuned threshold on TEST (predict class 0 if p0 >= thr*)\n",
    "p0_test = 1.0 - proba_test\n",
    "y_pred_tuned0 = (p0_test >= best_thr_for_class0).astype(int)  # 1 -> class 0\n",
    "y_pred_tuned = np.where(y_pred_tuned0 == 1, 0, 1)  # map back: 0/1 originales\n",
    "\n",
    "print(\"\\n=== Confusion Matrix (LogReg balanced, tuned threshold) ===\")\n",
    "print(confusion_matrix(y_test, y_pred_tuned))\n",
    "print(\"\\n=== Classification Report (LogReg balanced, tuned threshold) ===\")\n",
    "print(classification_report(y_test, y_pred_tuned, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df2fae3-d503-4b57-a06a-3e30d419ee23",
   "metadata": {},
   "source": [
    "En este bloque se entrena un Random Forest con balanceo de clases para predecir el cumplimiento (≤2 horas) en Triage III. Se reporta el desempeño con umbral 0.5 y con un umbral ajustado para maximizar el F1 de la clase 0 (no cumplió ≤2 horas) usando el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "712f53f9-9101-471c-a924-d64fc641c43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix (RF balanced, thr=0.5) ===\n",
      "[[ 972 1148]\n",
      " [3299 5272]]\n",
      "\n",
      "=== Classification Report (RF balanced, thr=0.5) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.228     0.458     0.304      2120\n",
      "           1      0.821     0.615     0.703      8571\n",
      "\n",
      "    accuracy                          0.584     10691\n",
      "   macro avg      0.524     0.537     0.504     10691\n",
      "weighted avg      0.703     0.584     0.624     10691\n",
      "\n",
      "\n",
      "Best threshold for class 0 (train): 0.5024\n",
      "\n",
      "=== Confusion Matrix (RF balanced, tuned threshold) ===\n",
      "[[ 920 1200]\n",
      " [3065 5506]]\n",
      "\n",
      "=== Classification Report (RF balanced, tuned threshold) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.231     0.434     0.301      2120\n",
      "           1      0.821     0.642     0.721      8571\n",
      "\n",
      "    accuracy                          0.601     10691\n",
      "   macro avg      0.526     0.538     0.511     10691\n",
      "weighted avg      0.704     0.601     0.638     10691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Block 15 — Random Forest (balanced) + threshold tuning for class 0\n",
    "# Train a random forest with class weighting and tune threshold to improve class-0 detection\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
    "\n",
    "# Rebuild features consistently with Block 12 (Triage III subset already aplicado)\n",
    "features = ['EdadAtencion', 'Genero', 'min_registro_a_triage']\n",
    "X_train_rf = X_train[features].copy()\n",
    "X_test_rf  = X_test[features].copy()\n",
    "y_train_rf = y_train.astype(int).copy()\n",
    "y_test_rf  = y_test.astype(int).copy()\n",
    "\n",
    "# Preprocessor: imputación + escalado (num), imputación + one-hot (cat)\n",
    "num_features = ['EdadAtencion', 'min_registro_a_triage']\n",
    "cat_features = ['Genero']\n",
    "\n",
    "preprocessor_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), num_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('ohe', OneHotEncoder(drop='if_binary', handle_unknown='ignore'))\n",
    "        ]), cat_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Modelo: Random Forest con balance de clases\n",
    "rf_pipe = Pipeline(steps=[\n",
    "    ('prep', preprocessor_rf),\n",
    "    ('clf', RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=10,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Entrenamiento\n",
    "rf_pipe.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "# --- Evaluación con umbral 0.5 ---\n",
    "proba_test = rf_pipe.predict_proba(X_test_rf)[:, 1]  # P(y=1: cumple ≤2h)\n",
    "y_pred_default = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "print(\"=== Confusion Matrix (RF balanced, thr=0.5) ===\")\n",
    "print(confusion_matrix(y_test_rf, y_pred_default))\n",
    "print(\"\\n=== Classification Report (RF balanced, thr=0.5) ===\")\n",
    "print(classification_report(y_test_rf, y_pred_default, digits=3))\n",
    "\n",
    "# --- Ajuste de umbral para optimizar F1 de la clase 0 en TRAIN ---\n",
    "proba_train = rf_pipe.predict_proba(X_train_rf)[:, 1]\n",
    "p0_train = 1.0 - proba_train                 # prob de clase 0\n",
    "y0_train = (y_train_rf == 0).astype(int)     # 1 cuando es clase 0\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y0_train, p0_train)\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    f1_0 = np.where((prec + rec) > 0, 2 * prec * rec / (prec + rec), 0.0)\n",
    "\n",
    "if thr.size > 0:\n",
    "    f1_aligned = f1_0[1:] if f1_0.size > 1 else f1_0\n",
    "    best_idx = int(np.argmax(f1_aligned)) if f1_aligned.size > 0 else 0\n",
    "    best_thr_for_class0 = thr[best_idx]\n",
    "else:\n",
    "    best_thr_for_class0 = 0.5\n",
    "\n",
    "print(f\"\\nBest threshold for class 0 (train): {best_thr_for_class0:.4f}\")\n",
    "\n",
    "# Aplicar umbral ajustado en TEST: predecir 0 si p0 >= thr*\n",
    "p0_test = 1.0 - proba_test\n",
    "y_pred_tuned0 = (p0_test >= best_thr_for_class0).astype(int)   # 1 -> clase 0\n",
    "y_pred_tuned = np.where(y_pred_tuned0 == 1, 0, 1)              # map a etiquetas originales\n",
    "\n",
    "print(\"\\n=== Confusion Matrix (RF balanced, tuned threshold) ===\")\n",
    "print(confusion_matrix(y_test_rf, y_pred_tuned))\n",
    "print(\"\\n=== Classification Report (RF balanced, tuned threshold) ===\")\n",
    "print(classification_report(y_test_rf, y_pred_tuned, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4729e9a0-f8fb-424f-97f6-e35be8129f3a",
   "metadata": {},
   "source": [
    "En este bloque se valida que las columnas existan, que no haya valores nulos/infinito en las features, que las clases estén bien definidas y que los tamaños de X/y coincidan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "540293ea-2b4e-435c-b9e3-709cdc9653ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns in df_triage3: []\n",
      "Shapes -> X_train: (24944, 3)  y_train: (24944,)  | X_test: (10691, 3)  y_test: (10691,)\n",
      "\n",
      "Dtypes of X_train:\n",
      " EdadAtencion               int64\n",
      "Genero                    object\n",
      "min_registro_a_triage    float64\n",
      "dtype: object\n",
      "NaN/inf in EdadAtencion -> NaN:0 | Inf:0\n",
      "NaN/inf in min_registro_a_triage -> NaN:0 | Inf:0\n",
      "\n",
      "Unique values in Genero: ['Masculino' 'Femenino']\n",
      "\n",
      "Distribution of y_train:\n",
      "target\n",
      "1    19997\n",
      "0     4947\n",
      "Name: count, dtype: int64\n",
      "Distribution of y_test:\n",
      "target\n",
      "1    8571\n",
      "0    2120\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Index alignment -> Train: True  | Test: True\n"
     ]
    }
   ],
   "source": [
    "# Block 16 — Quick diagnostic check (corrected version)\n",
    "# This block verifies required columns, shapes, data types, missing values, and index alignment\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "req_cols = ['EdadAtencion', 'Genero', 'min_registro_a_triage', 'target']\n",
    "missing = [c for c in req_cols if c not in df_triage3.columns]\n",
    "print(\"Missing columns in df_triage3:\", missing)\n",
    "\n",
    "# Check shapes\n",
    "print(\"Shapes -> X_train:\", X_train.shape, \" y_train:\", y_train.shape,\n",
    "      \" | X_test:\", X_test.shape, \" y_test:\", y_test.shape)\n",
    "\n",
    "# Check dtypes and NaN/inf\n",
    "X_probe = X_train.copy()\n",
    "print(\"\\nDtypes of X_train:\\n\", X_probe.dtypes)\n",
    "\n",
    "num_cols = [c for c in ['EdadAtencion','min_registro_a_triage'] if c in X_probe.columns]\n",
    "for c in num_cols:\n",
    "    s = pd.to_numeric(X_probe[c], errors='coerce')\n",
    "    n_nan = s.isna().sum()\n",
    "    n_inf = np.isinf(s.to_numpy()).sum()\n",
    "    print(f\"NaN/inf in {c} -> NaN:{n_nan} | Inf:{n_inf}\")\n",
    "\n",
    "# Categorical column\n",
    "if 'Genero' in X_probe.columns:\n",
    "    print(\"\\nUnique values in Genero:\", X_probe['Genero'].dropna().unique()[:10])\n",
    "\n",
    "# Target distribution\n",
    "print(\"\\nDistribution of y_train:\")\n",
    "print(y_train.value_counts(dropna=False))\n",
    "print(\"Distribution of y_test:\")\n",
    "print(y_test.value_counts(dropna=False))\n",
    "\n",
    "# Index alignment\n",
    "ok_index_train = X_train.index.isin(y_train.index).all()\n",
    "ok_index_test = X_test.index.isin(y_test.index).all()\n",
    "print(\"\\nIndex alignment -> Train:\", ok_index_train, \" | Test:\", ok_index_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e48cd-741b-4d8f-bc73-26737b06c600",
   "metadata": {},
   "source": [
    "En este bloque se generan variables de contexto para pacientes de Triage III: hora de atención, día de la semana, indicador de fin de semana, mes y una medida de congestión (arrivals_60m, número de llegadas en los 60 minutos previos). Estas características buscan capturar factores operativos que pueden influir en el cumplimiento del estándar de dos horas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4b5ec21-cdf5-417e-b0fe-0ed806161f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> X_train_fe: (24959, 8) X_test_fe: (10702, 8)\n",
      "Preview engineered columns:\n",
      "        EdadAtencion     Genero  min_registro_a_triage  hour  dow  is_weekend  month  arrivals_60m\n",
      "10330            19  Masculino              11.866667    21    4           0      6           3.0\n",
      "12759            25   Femenino              11.016667    16    0           0      1           5.0\n",
      "10463            37   Femenino               3.050000     0    2           0      9           4.0\n"
     ]
    }
   ],
   "source": [
    "# Block 17 — Feature engineering for Triage III (time & congestion)\n",
    "# Add hour, day-of-week, weekend, month, and arrivals in prior 60 minutes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure datetime\n",
    "df_triage3['FechaTriage'] = pd.to_datetime(df_triage3['FechaTriage'], errors='coerce')\n",
    "\n",
    "# Time-based features\n",
    "df_triage3['hour']       = df_triage3['FechaTriage'].dt.hour\n",
    "df_triage3['dow']        = df_triage3['FechaTriage'].dt.dayofweek   # 0=Mon ... 6=Sun\n",
    "df_triage3['is_weekend'] = (df_triage3['dow'] >= 5).astype(int)\n",
    "df_triage3['month']      = df_triage3['FechaTriage'].dt.month\n",
    "\n",
    "# Congestion proxy: arrivals in the previous 60 minutes (excluding current)\n",
    "df_tmp = df_triage3[['FechaTriage']].copy()\n",
    "df_tmp = df_tmp.sort_values('FechaTriage').set_index('FechaTriage')\n",
    "df_tmp['ones'] = 1\n",
    "df_tmp['arrivals_60m'] = df_tmp['ones'].rolling('60min').sum() - 1\n",
    "df_tmp['arrivals_60m'] = df_tmp['arrivals_60m'].clip(lower=0).fillna(0)\n",
    "\n",
    "# Merge back\n",
    "df_triage3 = df_triage3.join(df_tmp['arrivals_60m'], on='FechaTriage')\n",
    "\n",
    "# Feature set with engineered features\n",
    "features_fe = [\n",
    "    'EdadAtencion', 'Genero',\n",
    "    'min_registro_a_triage',     # existing signal\n",
    "    'hour', 'dow', 'is_weekend', 'month',  # calendar/time\n",
    "    'arrivals_60m'               # congestion proxy\n",
    "]\n",
    "\n",
    "# Align to existing train/test split\n",
    "X_train_fe = df_triage3.loc[X_train.index, features_fe].copy()\n",
    "X_test_fe  = df_triage3.loc[X_test.index,  features_fe].copy()\n",
    "y_train_fe = df_triage3.loc[y_train.index, 'target'].astype(int).copy()\n",
    "y_test_fe  = df_triage3.loc[y_test.index,  'target'].astype(int).copy()\n",
    "\n",
    "print(\"Shapes -> X_train_fe:\", X_train_fe.shape, \"X_test_fe:\", X_test_fe.shape)\n",
    "print(\"Preview engineered columns:\\n\", X_train_fe.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d447c6-3d09-4ac5-9ecd-545682eefc6b",
   "metadata": {},
   "source": [
    "En este bloque se entrena un modelo de Random Forest balanceado utilizando las nuevas variables de contexto generadas en el bloque anterior. Se evalúa el desempeño del modelo con el umbral estándar (0.5) y luego con un umbral ajustado para maximizar el F1 de la clase 0 (pacientes que no cumplen el estándar de dos horas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b72eef6-d4b3-4234-8eb2-054ffccdb2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix (RF+FE, thr=0.5) ===\n",
      "[[1702  422]\n",
      " [2076 6502]]\n",
      "\n",
      "=== Classification Report (RF+FE, thr=0.5) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.451     0.801     0.577      2124\n",
      "           1      0.939     0.758     0.839      8578\n",
      "\n",
      "    accuracy                          0.767     10702\n",
      "   macro avg      0.695     0.780     0.708     10702\n",
      "weighted avg      0.842     0.767     0.787     10702\n",
      "\n",
      "\n",
      "Best threshold for class 0 (train): 0.5721\n",
      "\n",
      "=== Confusion Matrix (RF+FE, tuned threshold) ===\n",
      "[[1476  648]\n",
      " [1477 7101]]\n",
      "\n",
      "=== Classification Report (RF+FE, tuned threshold) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.695     0.581      2124\n",
      "           1      0.916     0.828     0.870      8578\n",
      "\n",
      "    accuracy                          0.801     10702\n",
      "   macro avg      0.708     0.761     0.726     10702\n",
      "weighted avg      0.834     0.801     0.813     10702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Block 18 — Random Forest (balanced) with engineered features + tuned threshold\n",
    "# Refit RF using engineered features and compare performance\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "# Split features into numeric and categorical\n",
    "num_features = ['EdadAtencion','min_registro_a_triage','hour','dow','is_weekend','month','arrivals_60m']\n",
    "cat_features = ['Genero']\n",
    "\n",
    "preprocessor_rf_fe = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), num_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('ohe', OneHotEncoder(drop='if_binary', handle_unknown='ignore'))\n",
    "        ]), cat_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "rf_pipe_fe = Pipeline(steps=[\n",
    "    ('prep', preprocessor_rf_fe),\n",
    "    ('clf', RandomForestClassifier(\n",
    "        n_estimators=350,\n",
    "        max_depth=10,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit\n",
    "rf_pipe_fe.fit(X_train_fe, y_train_fe)\n",
    "\n",
    "# --- thr=0.5 ---\n",
    "proba_test = rf_pipe_fe.predict_proba(X_test_fe)[:, 1]\n",
    "y_pred_default = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "print(\"=== Confusion Matrix (RF+FE, thr=0.5) ===\")\n",
    "print(confusion_matrix(y_test_fe, y_pred_default))\n",
    "print(\"\\n=== Classification Report (RF+FE, thr=0.5) ===\")\n",
    "print(classification_report(y_test_fe, y_pred_default, digits=3))\n",
    "\n",
    "# --- threshold tuning for class 0 (maximize F1_0 on train) ---\n",
    "proba_train = rf_pipe_fe.predict_proba(X_train_fe)[:, 1]\n",
    "p0_train = 1.0 - proba_train\n",
    "y0_train = (y_train_fe == 0).astype(int)\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y0_train, p0_train)\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    f1_0 = np.where((prec + rec) > 0, 2 * prec * rec / (prec + rec), 0.0)\n",
    "\n",
    "if thr.size > 0 and f1_0.size > 1:\n",
    "    f1_aligned = f1_0[1:]\n",
    "    best_idx = int(np.argmax(f1_aligned))\n",
    "    best_thr_for_class0 = thr[best_idx]\n",
    "else:\n",
    "    best_thr_for_class0 = 0.5\n",
    "\n",
    "print(f\"\\nBest threshold for class 0 (train): {best_thr_for_class0:.4f}\")\n",
    "\n",
    "# Apply tuned threshold on TEST\n",
    "p0_test = 1.0 - proba_test\n",
    "y_pred_tuned0 = (p0_test >= best_thr_for_class0).astype(int)  # 1 -> class 0\n",
    "y_pred_tuned = np.where(y_pred_tuned0 == 1, 0, 1)\n",
    "\n",
    "print(\"\\n=== Confusion Matrix (RF+FE, tuned threshold) ===\")\n",
    "print(confusion_matrix(y_test_fe, y_pred_tuned))\n",
    "print(\"\\n=== Classification Report (RF+FE, tuned threshold) ===\")\n",
    "print(classification_report(y_test_fe, y_pred_tuned, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da1300-ef3b-4980-8d84-b290fa476382",
   "metadata": {},
   "source": [
    "En este bloque se entrena XGBoost con las variables de contexto (tiempo y congestión) usando un Pipeline de preprocesamiento. Se reportan resultados con umbral 0.5 y con umbral ajustado para maximizar el F1 de la clase 0 (no cumplimiento del estándar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56983416-7808-424e-8eea-7aa9fde03bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix (XGB+FE, thr=0.5) ===\n",
      "[[ 948 1176]\n",
      " [ 515 8063]]\n",
      "\n",
      "=== Classification Report (XGB+FE, thr=0.5) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.648     0.446     0.529      2124\n",
      "           1      0.873     0.940     0.905      8578\n",
      "\n",
      "    accuracy                          0.842     10702\n",
      "   macro avg      0.760     0.693     0.717     10702\n",
      "weighted avg      0.828     0.842     0.830     10702\n",
      "\n",
      "\n",
      "Best threshold for class 0 (train): 0.3517\n",
      "\n",
      "=== Confusion Matrix (XGB+FE, tuned threshold) ===\n",
      "[[1345  779]\n",
      " [1033 7545]]\n",
      "\n",
      "=== Classification Report (XGB+FE, tuned threshold) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.566     0.633     0.598      2124\n",
      "           1      0.906     0.880     0.893      8578\n",
      "\n",
      "    accuracy                          0.831     10702\n",
      "   macro avg      0.736     0.756     0.745     10702\n",
      "weighted avg      0.839     0.831     0.834     10702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Block 19 — XGBoost with engineered features (no early stopping) + tuned threshold\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"XGBoost no está instalado. Instalar con: pip install xgboost\") from e\n",
    "\n",
    "# Features consistentes con Block 18\n",
    "num_features = ['EdadAtencion','min_registro_a_triage','hour','dow','is_weekend','month','arrivals_60m']\n",
    "cat_features = ['Genero']\n",
    "\n",
    "# Preprocesador\n",
    "preprocessor_xgb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), num_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('ohe', OneHotEncoder(drop='if_binary', handle_unknown='ignore'))\n",
    "        ]), cat_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Modelo XGBoost (sin early stopping)\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    min_child_weight=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_pipe = Pipeline(steps=[\n",
    "    ('prep', preprocessor_xgb),\n",
    "    ('clf', xgb)\n",
    "])\n",
    "\n",
    "# Entrenamiento\n",
    "xgb_pipe.fit(X_train_fe, y_train_fe)\n",
    "\n",
    "# === Evaluación con umbral 0.5 ===\n",
    "proba_test = xgb_pipe.predict_proba(X_test_fe)[:, 1]  # P(y=1: cumple ≤2h)\n",
    "y_pred_default = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "print(\"=== Confusion Matrix (XGB+FE, thr=0.5) ===\")\n",
    "print(confusion_matrix(y_test_fe, y_pred_default))\n",
    "print(\"\\n=== Classification Report (XGB+FE, thr=0.5) ===\")\n",
    "print(classification_report(y_test_fe, y_pred_default, digits=3))\n",
    "\n",
    "# === Ajuste de umbral para maximizar F1 de la clase 0 (no cumple ≤2h) ===\n",
    "proba_train = xgb_pipe.predict_proba(X_train_fe)[:, 1]\n",
    "p0_train = 1.0 - proba_train\n",
    "y0_train = (y_train_fe == 0).astype(int)\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y0_train, p0_train)\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    f1_0 = np.where((prec + rec) > 0, 2 * prec * rec / (prec + rec), 0.0)\n",
    "\n",
    "if thr.size > 0 and f1_0.size > 1:\n",
    "    f1_aligned = f1_0[1:]\n",
    "    best_idx = int(np.argmax(f1_aligned))\n",
    "    best_thr_for_class0 = thr[best_idx]\n",
    "else:\n",
    "    best_thr_for_class0 = 0.5\n",
    "\n",
    "print(f\"\\nBest threshold for class 0 (train): {best_thr_for_class0:.4f}\")\n",
    "\n",
    "# Aplicación del umbral ajustado en TEST\n",
    "p0_test = 1.0 - proba_test\n",
    "y_pred_tuned0 = (p0_test >= best_thr_for_class0).astype(int)  # 1 -> clase 0\n",
    "y_pred_tuned = np.where(y_pred_tuned0 == 1, 0, 1)\n",
    "\n",
    "print(\"\\n=== Confusion Matrix (XGB+FE, tuned threshold) ===\")\n",
    "print(confusion_matrix(y_test_fe, y_pred_tuned))\n",
    "print(\"\\n=== Classification Report (XGB+FE, tuned threshold) ===\")\n",
    "print(classification_report(y_test_fe, y_pred_tuned, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bb9b69-8b5b-4122-8df1-217661925341",
   "metadata": {},
   "source": [
    "All models above don't consider the text in MotivoConsulta, available in Triage.\n",
    "\n",
    "Now the text is modelled as topic to use in the ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a02d73-71f0-4995-8b92-c64c5ad600e9",
   "metadata": {},
   "source": [
    "En este bloque se construye una tabla comparativa entre los modelos Random Forest y XGBoost con las variables de contexto. Además, se realiza un barrido de umbrales en XGBoost para identificar el punto operativo que maximiza el F1 de la clase 0 y permite observar cómo cambian las métricas (precision, recall y F1) de ambas clases según el umbral de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e48777ff-e77e-4808-bc65-64202858c180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model comparison ===\n",
      "                        Model  Accuracy  Recall_0  Precision_0   F1_0  Recall_1  Precision_1   F1_1\n",
      "0  Random Forest + FE (tuned)     0.801     0.695        0.500  0.581     0.828        0.916  0.870\n",
      "1        XGBoost + FE (tuned)     0.831     0.633        0.566  0.598     0.880        0.906  0.893\n",
      "\n",
      "=== Threshold sweep for XGBoost ===\n",
      "   Threshold  Accuracy  Recall_0  Precision_0   F1_0  Recall_1  Precision_1   F1_1\n",
      "0       0.10     0.806     0.024        0.912  0.048     0.999        0.805  0.892\n",
      "1       0.15     0.811     0.058        0.866  0.109     0.998        0.811  0.894\n",
      "2       0.20     0.818     0.098        0.850  0.176     0.996        0.817  0.897\n",
      "3       0.25     0.826     0.158        0.821  0.265     0.991        0.826  0.901\n",
      "4       0.30     0.834     0.219        0.792  0.343     0.986        0.836  0.905\n",
      "5       0.35     0.837     0.267        0.749  0.394     0.978        0.843  0.906\n",
      "6       0.40     0.841     0.330        0.716  0.451     0.968        0.854  0.907\n",
      "7       0.45     0.844     0.392        0.686  0.499     0.956        0.864  0.907\n",
      "8       0.50     0.842     0.446        0.648  0.529     0.940        0.873  0.905\n",
      "9       0.55     0.842     0.512        0.624  0.562     0.924        0.884  0.904\n",
      "\n",
      "Best threshold for F1_0: 0.700\n",
      "Threshold      0.700000\n",
      "Accuracy       0.821622\n",
      "Recall_0       0.699153\n",
      "Precision_0    0.539020\n",
      "F1_0           0.608731\n",
      "Recall_1       0.851947\n",
      "Precision_1    0.919592\n",
      "F1_1           0.884478\n",
      "Name: 12, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Block 20 — Model comparison (RF vs XGB) + threshold sweep for XGBoost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
    "\n",
    "# === 1. Compare RF vs XGB at tuned thresholds ===\n",
    "# Metrics for RF (already computed in Block 18 tuned)\n",
    "rf_metrics = {\n",
    "    \"Model\": \"Random Forest + FE (tuned)\",\n",
    "    \"Accuracy\": 0.801,\n",
    "    \"Recall_0\": 0.695,\n",
    "    \"Precision_0\": 0.500,\n",
    "    \"F1_0\": 0.581,\n",
    "    \"Recall_1\": 0.828,\n",
    "    \"Precision_1\": 0.916,\n",
    "    \"F1_1\": 0.870\n",
    "}\n",
    "\n",
    "# Metrics for XGB (already computed in Block 19 tuned)\n",
    "xgb_metrics = {\n",
    "    \"Model\": \"XGBoost + FE (tuned)\",\n",
    "    \"Accuracy\": 0.831,\n",
    "    \"Recall_0\": 0.633,\n",
    "    \"Precision_0\": 0.566,\n",
    "    \"F1_0\": 0.598,\n",
    "    \"Recall_1\": 0.880,\n",
    "    \"Precision_1\": 0.906,\n",
    "    \"F1_1\": 0.893\n",
    "}\n",
    "\n",
    "df_compare = pd.DataFrame([rf_metrics, xgb_metrics])\n",
    "print(\"=== Model comparison ===\")\n",
    "print(df_compare)\n",
    "\n",
    "# === 2. Threshold sweep for XGBoost ===\n",
    "proba_test_xgb = xgb_pipe.predict_proba(X_test_fe)[:, 1]\n",
    "y_true = y_test_fe\n",
    "\n",
    "thresholds = np.linspace(0.1, 0.9, 17)  # from 0.1 to 0.9 step 0.05\n",
    "rows = []\n",
    "\n",
    "for thr in thresholds:\n",
    "    y_pred = (proba_test_xgb >= thr).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    prec0 = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    rec0 = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    f1_0 = (2*prec0*rec0)/(prec0+rec0) if (prec0+rec0) > 0 else 0\n",
    "    prec1 = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    rec1 = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_1 = (2*prec1*rec1)/(prec1+rec1) if (prec1+rec1) > 0 else 0\n",
    "    acc = (tn+tp)/(tn+fp+fn+tp)\n",
    "    \n",
    "    rows.append({\n",
    "        \"Threshold\": thr,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Recall_0\": rec0,\n",
    "        \"Precision_0\": prec0,\n",
    "        \"F1_0\": f1_0,\n",
    "        \"Recall_1\": rec1,\n",
    "        \"Precision_1\": prec1,\n",
    "        \"F1_1\": f1_1\n",
    "    })\n",
    "\n",
    "df_thr = pd.DataFrame(rows)\n",
    "print(\"\\n=== Threshold sweep for XGBoost ===\")\n",
    "print(df_thr.round(3).head(10))  # preview first 10 rows\n",
    "\n",
    "# Show best threshold for F1_0\n",
    "best_idx = df_thr['F1_0'].idxmax()\n",
    "best_thr = df_thr.loc[best_idx, 'Threshold']\n",
    "print(f\"\\nBest threshold for F1_0: {best_thr:.3f}\")\n",
    "print(df_thr.loc[best_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36efaad5-fa98-487e-b36f-6acedf098e60",
   "metadata": {},
   "source": [
    "En este bloque se construyen variables temáticas a partir de los textos de la columna MotivoConsulta. Para ello, primero se deduplican los registros a fin de evitar inconsistencias en los índices y se alinean con las matrices de entrenamiento y prueba previamente definidas. Posteriormente, se aplica un modelo de TF-IDF para representar los textos y, sobre esa base, se utiliza NMF para identificar diez tópicos latentes. Los puntajes de pertenencia a cada tópico se integran como nuevas variables predictoras en las matrices de entrenamiento y prueba, enriqueciendo así las características disponibles para los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3cb6f1a-f7ad-434f-83f7-c9b5bbe43bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned shapes OK -> TF-IDF: (24959, 14276) (10702, 14276) | Topics: (24959, 10) (10702, 10) | Matrices: (24959, 18) (10702, 18)\n"
     ]
    }
   ],
   "source": [
    "# Block 21 — Topic features from MotivoConsulta (TF-IDF + NMF) — DEDUP & ALIGN\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "assert 'MotivoConsulta' in df_triage3.columns, \"MotivoConsulta column is required\"\n",
    "assert isinstance(X_train_fe, pd.DataFrame) and isinstance(X_test_fe, pd.DataFrame), \"Run Block 17 first\"\n",
    "\n",
    "# 1) Deduplicate df_triage3 by index (keep first) to guarantee 1:1 mapping by label\n",
    "df_triage3_dedup = (\n",
    "    df_triage3[['MotivoConsulta']]\n",
    "    .astype(str)\n",
    "    .groupby(level=0, sort=False)\n",
    "    .nth(0)\n",
    ")\n",
    "\n",
    "# 2) Now align EXACTLY to the indices and order of X_train_fe / X_test_fe\n",
    "idx_train = X_train_fe.index\n",
    "idx_test  = X_test_fe.index\n",
    "\n",
    "# Reindex is safe now because df_triage3_dedup has unique index labels\n",
    "text_train = df_triage3_dedup.reindex(idx_train)['MotivoConsulta'].fillna(\"\").astype(str)\n",
    "text_test  = df_triage3_dedup.reindex(idx_test)['MotivoConsulta'].fillna(\"\").astype(str)\n",
    "\n",
    "# Hard checks\n",
    "assert len(text_train) == len(X_train_fe), f\"Train length mismatch: {len(text_train)} vs {len(X_train_fe)}\"\n",
    "assert len(text_test)  == len(X_test_fe),  f\"Test length mismatch: {len(text_test)} vs {len(X_test_fe)}\"\n",
    "assert text_train.index.equals(X_train_fe.index)\n",
    "assert text_test.index.equals(X_test_fe.index)\n",
    "\n",
    "# 3) TF-IDF (sin 'spanish' para evitar error de sklearn)\n",
    "tfidf = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    strip_accents='unicode',\n",
    "    min_df=10,\n",
    "    max_df=0.9,\n",
    "    ngram_range=(1,2),\n",
    "    max_features=20000\n",
    ")\n",
    "X_tfidf_train = tfidf.fit_transform(text_train)\n",
    "X_tfidf_test  = tfidf.transform(text_test)\n",
    "\n",
    "# 4) NMF topics\n",
    "n_topics = 10\n",
    "nmf = NMF(n_components=n_topics, init='nndsvd', random_state=42, max_iter=400)\n",
    "W_train = nmf.fit_transform(X_tfidf_train)\n",
    "W_test  = nmf.transform(X_tfidf_test)\n",
    "\n",
    "topic_cols = [f\"topic_{i+1}\" for i in range(n_topics)]\n",
    "topic_train_df = pd.DataFrame(W_train, index=X_train_fe.index, columns=topic_cols)\n",
    "topic_test_df  = pd.DataFrame(W_test,  index=X_test_fe.index,  columns=topic_cols)\n",
    "\n",
    "# 5) Concatenate with engineered features\n",
    "X_train_topics = pd.concat([X_train_fe, topic_train_df], axis=1)\n",
    "X_test_topics  = pd.concat([X_test_fe,  topic_test_df],  axis=1)\n",
    "\n",
    "print(\"Aligned shapes OK ->\",\n",
    "      \"TF-IDF:\", X_tfidf_train.shape, X_tfidf_test.shape,\n",
    "      \"| Topics:\", W_train.shape, W_test.shape,\n",
    "      \"| Matrices:\", X_train_topics.shape, X_test_topics.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa19f4-508c-49db-b3a6-42d80ae73280",
   "metadata": {},
   "source": [
    "En este bloque se inspeccionan los tópicos generados a partir de MotivoConsulta. Primero, se listan las palabras más representativas de cada tópico; luego, se calcula la prevalencia de cada uno en el conjunto de entrenamiento asignando a cada registro el tópico con mayor peso; finalmente, se muestran ejemplos de textos con mayor contribución por tópico. No se incluyen visualizaciones gráficas para mantener la trazabilidad del pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0980c5db-8558-4423-85a8-97791339073f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top palabras por tópico ===\n",
      "      topic                                          top_words\n",
      "0   topic_1  niega_x000d_, por, realiza, se realiza, _x000d...\n",
      "1   topic_2  refiere, niega_x000d_, el siguiente, siguiente...\n",
      "2   topic_3  los, covid 19, 19, 15, valoracion, covid, _x00...\n",
      "3   topic_4  riesgo, riesgo de, _x000d_ riesgo, farmacologi...\n",
      "4   topic_5  niega _x000d_, niega, por, alergico niega, _x0...\n",
      "5   topic_6  el, refiere, aproximado paciente, aproximado, ...\n",
      "6   topic_7  trauma, limitacion, trauma en, mano, la, edema...\n",
      "7   topic_8  _x000d_ _x000d_, paciente al, ingresa paciente...\n",
      "8   topic_9  15, valoracion, para, paciente refiere, brinda...\n",
      "9  topic_10  normales, signos vitales, vitales, con signos,...\n",
      "\n",
      "=== Prevalencia de tópicos (train) ===\n",
      "      topic  count  proportion\n",
      "0   topic_1   4449    0.178252\n",
      "1   topic_2   2687    0.107657\n",
      "2   topic_3    704    0.028206\n",
      "3   topic_4    770    0.030851\n",
      "4   topic_5   5809    0.232742\n",
      "5   topic_6   1778    0.071237\n",
      "6   topic_7   2073    0.083056\n",
      "7   topic_8   3888    0.155775\n",
      "8   topic_9    516    0.020674\n",
      "9  topic_10   2285    0.091550\n",
      "\n",
      "=== Ejemplos por tópico (top contribuciones) ===\n",
      "\n",
      "-- topic_1: ejemplos (n=5) --\n",
      " 1. weight=0.107 | idx=17381 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud.  _x000D_  _x000D_ Motivo de consulta:  “me duele el estómago ”_x000D_ _x000D_ Paciente con cuadro de más o men…\n",
      " 2. weight=0.103 | idx=28022 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2. _x000D_ _x000D_ Motivo de consulta “  dolor abdominal …\n",
      " 3. weight=0.102 | idx=43767 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud.   _x000D_ _x000D_ Motivo de consulta:  “ me duele el estómago ”_x000D_ _x000D_ Paciente con cuadro de más o me…\n",
      " 4. weight=0.101 | idx=8581 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la oms y ministerio de salud; correspondientes a emergencia sanitaria por sars cov 2. _x000D_ _x000D_ Motivo de consulta “dolor de estomago …\n",
      " 5. weight=0.100 | idx=1257 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2. _x000D_ Motivo de consulta “ dolor de cabeza ”_x000D_ …\n",
      "\n",
      "-- topic_2: ejemplos (n=5) --\n",
      " 1. weight=0.138 | idx=1497 | Ingresa al servicio de urgencias paciente masculino de 23 años con el siguiente motivo de consulta: “ me duele mucho aquí  “_x000D_ _x000D_ paciente con cuadro clínico de más o menos 1 días de evolución consistente en do…\n",
      " 2. weight=0.132 | idx=2603 | Ingresa al servicio de urgencias paciente masculino de 20  años con el siguiente motivo de consulta: “ me duele mucho aquí “_x000D_ _x000D_ paciente con cuadro clínico de más o menos 8 horas de evolución consistente en d…\n",
      " 3. weight=0.131 | idx=13201 | Ingresa al servicio de urgencias paciente femenino de 26 años con el siguiente motivo de consulta: “tengo gastritis “_x000D_ _x000D_ paciente con cuadro clínico de más o menos 3 días de evolución consistente en dolor abd…\n",
      " 4. weight=0.131 | idx=45504 | Ingresa al servicio de urgencias paciente masculino de 38  años con el siguiente motivo de consulta: “ me duele el estómago “_x000D_ _x000D_ paciente con cuadro clínico de más o menos 2 días de evolución consistente en d…\n",
      " 5. weight=0.130 | idx=12028 | Ingresa al servicio de urgencias paciente masculino de 29  años con el siguiente motivo de consulta: “ me empeoro el dolor “_x000D_ _x000D_ paciente con cuadro clínico de más o menos 3 días de evolución consistente en do…\n",
      "\n",
      "-- topic_3: ejemplos (n=5) --\n",
      " 1. weight=0.196 | idx=23023 | SE ATIENDE A PACIENTE SIGUIENDO TODOS LOS PROTOCOLOS INSTITUCIONALES Y RECOMENDACIONES DE LA OMS FRENTE A PANDEMIA POR COVID-19, ASI COMO EL USO COMPLETO Y CORRECTO DE LOS ELEMENTOS DE PROTECCIÓN PERSONAL (MONOGAFAS, RES…\n",
      " 2. weight=0.193 | idx=7632 | SE ATIENDE A PACIENTE SIGUIENDO TODOS LOS PROTOCOLOS INSTITUCIONALES Y RECOMENDACIONES DE LA OMS FRENTE A PANDEMIA POR COVID-19, ASI COMO EL USO COMPLETO Y CORRECTO DE LOS ELEMENTOS DE PROTECCIÓN PERSONAL (MONOGAFAS, RES…\n",
      " 3. weight=0.192 | idx=41383 | SE ATIENDE A PACIENTE SIGUIENDO TODOS LOS PROTOCOLOS INSTITUCIONALES Y RECOMENDACIONES DE LA OMS FRENTE A PANDEMIA POR COVID-19, ASI COMO EL USO COMPLETO Y CORRECTO DE LOS ELEMENTOS DE PROTECCIÓN PERSONAL (MONOGAFAS, RES…\n",
      " 4. weight=0.192 | idx=15610 | SE ATIENDE A PACIENTE SIGUIENDO TODOS LOS PROTOCOLOS INSTITUCIONALES Y RECOMENDACIONES DE LA OMS FRENTE A PANDEMIA POR COVID-19, ASI COMO EL USO COMPLETO Y CORRECTO DE LOS ELEMENTOS DE PROTECCIÓN PERSONAL (MONOGAFAS, RES…\n",
      " 5. weight=0.192 | idx=38145 | SE ATIENDE A PACIENTE SIGUIENDO TODOS LOS PROTOCOLOS INSTITUCIONALES Y RECOMENDACIONES DE LA OMS FRENTE A PANDEMIA POR COVID-19, ASI COMO EL USO COMPLETO Y CORRECTO DE LOS ELEMENTOS DE PROTECCIÓN PERSONAL (MONOGAFAS, RES…\n",
      "\n",
      "-- topic_4: ejemplos (n=5) --\n",
      " 1. weight=0.198 | idx=42909 | Ingresa paciente masculinoi de 532 años poprprsentarepisodios de perdia del equilbrio refiere nausea sy mareio se clasifica como triogae 3 _x000D_ _x000D_ _x000D_ Alergias farmacológicas: niega_x000D_ Riesgo de caída: Me…\n",
      " 2. weight=0.192 | idx=15136 | Ingresa paciente masculino de 18 años por prosentar ottorragia de 3 dias de evolucion paciewnte manifiesta cefalea y dolor maxilar se clasifica como trigae 3 _x000D_ _x000D_ Alergias farmacológicas: niega_x000D_ Riesgo d…\n",
      " 3. weight=0.191 | idx=18901 | Ingresa apciente masculino de 64 años por presentar _x000D_ _x000D_ Alergias farmacológicas: niega_x000D_ Riesgo de caída: Medio _x000D_ Riesgo de lesión de piel: Bajo _x000D_ _x000D_ *****En contexto actual postpandemia…\n",
      " 4. weight=0.185 | idx=2677 | Ingresa paciente masculino de 34 años porprpsentar dolor testicular  de 1 mes d evolucion exacerbado hace 3 dias; paciente refiere dolor migrante a region inguinla manifiesta antecednete de varicocele corregida; se clasi…\n",
      " 5. weight=0.185 | idx=34882 | Ingresa paciente masculino de 76 años por presentardolor abdominal de 1 dia d eevolucion paciente refiere nauseas 10 episodio emeticos se clasifica como trigae 3 _x000D_ _x000D_ Alergias farmacológicas: niega_x000D_ Ries…\n",
      "\n",
      "-- topic_5: ejemplos (n=5) --\n",
      " 1. weight=0.138 | idx=7063 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2. _x000D_ _x000D_ Motivo de consulta “tengo dolor abdomi…\n",
      " 2. weight=0.138 | idx=45434 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2. _x000D_ Motivo de consulta “tengo diarrea ___”_x000D_ …\n",
      " 3. weight=0.134 | idx=2196 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2. _x000D_ Motivo de consulta “dolor de estomago ”_x000D_…\n",
      " 4. weight=0.132 | idx=19783 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2. _x000D_ Motivo de consulta “_tego sonda 28/08/23___”_x…\n",
      " 5. weight=0.128 | idx=24959 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2. _x000D_ Motivo de consulta “_esta vomitando sangre_”_x…\n",
      "\n",
      "-- topic_6: ejemplos (n=5) --\n",
      " 1. weight=0.165 | idx=7313 | INGRESA AL SERVICIO DE URGENCIAS PACIENTE MASCULINO DE 28 AÑOS CON EL SIGUEINTE MOTIVO DE CONSULTA: TENGO DOLOR DE ESTOMAGO _x000D_ _x000D_ PACIENTE CON CUADRO CLINICO DE 2  DIAS DE EVOLUCION CONSISTENTE EN DOLOR ABDOMIN…\n",
      " 2. weight=0.162 | idx=4212 | INGRESA AL SERVICIO DE URGENCIAS PACIENTE FEMENINA DE 35  AÑOS CON EL SIGUEINTE MOTIVO DE CONSULTA: DOLOR DE ESTOMAGO_x000D_ _x000D_ PACIENTE CON CUADRO CLINICO DE 7 HORAS DE EVOLUCION CONSISTENTE EN DOLOR ABDOMINAL INTE…\n",
      " 3. weight=0.161 | idx=13801 | INGRESA AL SERVICIO DE URGENCIAS PACIENTE MASCULINO DE 33  AÑOS CON EL SIGUEINTE MOTIVO DE CONSULTA: DOLOR DE ESTOMAGO_x000D_ _x000D_ PACIENTE CON CUADRO CLINICO DE 1 DIA  DE EVOLUCION CONSISTENTE EN DOLOR ABDOMINAL FOCA…\n",
      " 4. weight=0.160 | idx=17487 | INGRESA AL SERVICIO DE URGENCIAS PACIENTE FEMENINA DE 23  AÑOS CON EL SIGUEINTE MOTIVO DE CONSULTA:  ME DUELE MUCHO LA BOCA_x000D_ _x000D_ PACIENTE CON CUADRO CLINICO DE 1 DIA DE EVOLUCION CONSISTENTE EN HERIDA IMPORTANT…\n",
      " 5. weight=0.158 | idx=11590 | INGRESA AL SERVICIO DE URGENCIAS PACIENTE 24 AÑOS CON EL SIGUEINTE MOTIVO DE CONSULTA: \"ME DUELE MUCHO ELE STOMAGO\"_x000D_ _x000D_ PACIENTE CON CUADRO CLINICO DE 2 DIAS DE EVOLUCION CONSISTENTE EN DOLOR EN EPIGASTRIO ASO…\n",
      "\n",
      "-- topic_7: ejemplos (n=5) --\n",
      " 1. weight=0.114 | idx=5362 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2. _x000D_ _x000D_ Motivo de consulta “  me cai ”_x000D_ …\n",
      " 2. weight=0.114 | idx=40013 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud. _x000D_ _x000D_ Motivo de consulta “Me caí ”_x000D_ _x000D_ Paciente con cuadro de más o menos 3 horas de evol…\n",
      " 3. weight=0.106 | idx=16754 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2. _x000D_ Motivo de consulta “ me caí y me duele el ´pie…\n",
      " 4. weight=0.105 | idx=26754 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la oms y ministerio de salud; correspondientes a emergencia sanitaria por sars cov 2. _x000D_ _x000D_ Motivo de consulta “ Me cai”_x000D_ _x…\n",
      " 5. weight=0.105 | idx=35888 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2. _x000D_ _x000D_ Motivo de consulta  “me cai “_x000D_ _…\n",
      "\n",
      "-- topic_8: ejemplos (n=5) --\n",
      " 1. weight=0.102 | idx=26851 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2._x000D_  _x000D_ Motivo de consulta “    ”_x000D_ _x000…\n",
      " 2. weight=0.099 | idx=22828 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la oms y ministerio de salud; correspondientes a emergencia sanitaria por sars cov 2. _x000D_ _x000D_ Motivo de consulta cefalea ”_x000D_ _x…\n",
      " 3. weight=0.098 | idx=1547 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la oms y ministerio de salud; correspondientes a emergencia sanitaria por sars cov 2. _x000D_ _x000D_ Motivo de consulta dolor abdominal ”_x…\n",
      " 4. weight=0.097 | idx=43737 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la oms y ministerio de salud; correspondientes a emergencia sanitaria por sars cov 2. _x000D_ _x000D_ Motivo de consulta dolor lumbar ”_x000…\n",
      " 5. weight=0.097 | idx=21913 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la oms y ministerio de salud; correspondientes a emergencia sanitaria por sars cov 2. _x000D_ _x000D_ Motivo de consulta dolor en miembro de…\n",
      "\n",
      "-- topic_9: ejemplos (n=5) --\n",
      " 1. weight=0.246 | idx=659 | Se atiende paciente con uso de elementos de protección personal brindados directamente por la institución. _x000D_ Ingresa paciente de 21 años de edad al servicio de urgencias, con motivo de consulta: “          me   eng…\n",
      " 2. weight=0.244 | idx=4550 | Se atiende paciente con uso de elementos de protección personal brindados directamente por la institución. _x000D_ Ingresa paciente de 36  años de edad al servicio de urgencias, con motivo de consulta: “     estaba  trab…\n",
      " 3. weight=0.244 | idx=6793 | Se atiende paciente con uso de elementos de protección personal brindados directamente por la institución. _x000D_ Ingresa paciente de 28 años de edad al servicio de urgencias, con motivo de consulta: “  por  que    acbo…\n",
      " 4. weight=0.241 | idx=1049 | Se atiende paciente con uso de elementos de protección personal brindados directamente por la institución. _x000D_ Ingresa paciente de 20 años de edad al servicio de urgencias, con motivo de consulta: “tengo dolor en el …\n",
      " 5. weight=0.240 | idx=19542 | Se atiende paciente con uso de elementos de protección personal brindados directamente por la institución. _x000D_ Ingresa paciente de 24 años de edad al servicio de urgencias, con motivo de consulta: “*  m redireccionad…\n",
      "\n",
      "-- topic_10: ejemplos (n=5) --\n",
      " 1. weight=0.150 | idx=28058 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2._x000D_  _x000D_ Motivo de consulta “Dolor abdominal”_x…\n",
      " 2. weight=0.140 | idx=5393 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2. _x000D_ _x000D_ Motivo de consulta “Dolor abdominal”_x…\n",
      " 3. weight=0.140 | idx=15811 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2._x000D_  _x000D_ Motivo de consulta “dolor abdominal”_x…\n",
      " 4. weight=0.135 | idx=11628 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2._x000D_  _x000D_ Motivo de consulta  ” Dolor abdominal …\n",
      " 5. weight=0.135 | idx=11011 | Se realiza atención del paciente, con medidas de bioseguridad, recomendadas por la OMS y ministerio de salud; correspondientes a emergencia sanitaria por SARS COV 2. _x000D_ _x000D_ Motivo de consulta  ” Me duelen los te…\n"
     ]
    }
   ],
   "source": [
    "# Block 21A — Topic inspection (no plots)\n",
    "# Requires Block 21 to have run (tfidf, nmf, topic_train_df)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Guard rails ---\n",
    "required = ['tfidf', 'nmf', 'topic_train_df', 'X_train_fe', 'df_triage3']\n",
    "missing = [name for name in required if name not in globals()]\n",
    "assert not missing, f\"Missing objects from Block 21: {missing}\"\n",
    "\n",
    "# 1) Top words per topic\n",
    "feature_names = np.array(tfidf.get_feature_names_out())\n",
    "\n",
    "def top_words_per_topic(model, feature_names, topn=12):\n",
    "    rows = []\n",
    "    for i, comp in enumerate(model.components_):\n",
    "        idx = np.argsort(comp)[::-1][:topn]\n",
    "        words = [feature_names[j] for j in idx]\n",
    "        rows.append({\n",
    "            \"topic\": f\"topic_{i+1}\",\n",
    "            \"top_words\": \", \".join(words)\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_top_words = top_words_per_topic(nmf, feature_names, topn=12)\n",
    "print(\"=== Top palabras por tópico ===\")\n",
    "print(df_top_words)\n",
    "\n",
    "# 2) Topic prevalence (hard assignment by argmax)\n",
    "W_train = topic_train_df.values  # document-topic weights (train)\n",
    "topic_idx = W_train.argmax(axis=1)  # winning topic per doc\n",
    "counts = pd.Series(topic_idx).value_counts().sort_index()\n",
    "prevalence = (counts / counts.sum()).rename(\"proportion\")\n",
    "df_prev = pd.DataFrame({\n",
    "    \"topic\": [f\"topic_{i+1}\" for i in range(W_train.shape[1])],\n",
    "    \"count\": counts.reindex(range(W_train.shape[1]), fill_value=0).values,\n",
    "    \"proportion\": prevalence.reindex(range(W_train.shape[1]), fill_value=0.0).values\n",
    "})\n",
    "print(\"\\n=== Prevalencia de tópicos (train) ===\")\n",
    "print(df_prev)\n",
    "\n",
    "# 3) Show top examples per topic\n",
    "# Utilities\n",
    "def truncate(text, n=180):\n",
    "    t = str(text).replace(\"\\n\", \" \").strip()\n",
    "    return (t[:n] + \"…\") if len(t) > n else t\n",
    "\n",
    "# Recuperar los textos de train alineados\n",
    "text_train = df_triage3.loc[X_train_fe.index, 'MotivoConsulta'].astype(str)\n",
    "\n",
    "n_examples = 5  # how many samples to print per topic\n",
    "print(\"\\n=== Ejemplos por tópico (top contribuciones) ===\")\n",
    "for t in range(W_train.shape[1]):\n",
    "    topic_name = f\"topic_{t+1}\"\n",
    "    # ordenar documentos por peso descendente en el tópico t\n",
    "    order = np.argsort(W_train[:, t])[::-1]\n",
    "    top_idx = X_train_fe.index[order][:n_examples]\n",
    "    top_weights = W_train[order, t][:n_examples]\n",
    "    print(f\"\\n-- {topic_name}: ejemplos (n={n_examples}) --\")\n",
    "    for i, (idx, w) in enumerate(zip(top_idx, top_weights), 1):\n",
    "        txt = truncate(text_train.loc[idx], 220)\n",
    "        print(f\"{i:>2}. weight={w:.3f} | idx={idx} | {txt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07642f7d-90e8-4b7b-b4d9-666d7fb48068",
   "metadata": {},
   "source": [
    "En este bloque se entrena un modelo de XGBoost que incorpora tanto las variables ingenierizadas como las características temáticas derivadas de MotivoConsulta. El modelo se evalúa inicialmente con un umbral estándar de 0.5 y luego con un umbral ajustado para maximizar el desempeño en la clase de incumplimiento (Triage III > 2 horas). Se presentan las matrices de confusión y los reportes de clasificación correspondientes, así como una comparación compacta de métricas clave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6929b192-5d12-4362-94af-844430fe337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> X_train_topics: (24959, 18)  X_test_topics: (10702, 18)\n",
      "=== Confusion Matrix (XGB+FE+Topics, thr=0.5) ===\n",
      "[[1000 1124]\n",
      " [ 411 8167]]\n",
      "\n",
      "=== Classification Report (XGB+FE+Topics, thr=0.5) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.709     0.471     0.566      2124\n",
      "           1      0.879     0.952     0.914      8578\n",
      "\n",
      "    accuracy                          0.857     10702\n",
      "   macro avg      0.794     0.711     0.740     10702\n",
      "weighted avg      0.845     0.857     0.845     10702\n",
      "\n",
      "\n",
      "Best threshold for class 0 (train): 0.3927\n",
      "\n",
      "=== Confusion Matrix (XGB+FE+Topics, tuned threshold) ===\n",
      "[[1263  861]\n",
      " [ 718 7860]]\n",
      "\n",
      "=== Classification Report (XGB+FE+Topics, tuned threshold) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.638     0.595     0.615      2124\n",
      "           1      0.901     0.916     0.909      8578\n",
      "\n",
      "    accuracy                          0.852     10702\n",
      "   macro avg      0.769     0.755     0.762     10702\n",
      "weighted avg      0.849     0.852     0.850     10702\n",
      "\n",
      "\n",
      "=== Compact comparison (tuned) ===\n",
      "                                     Model  Accuracy  Recall_0  Precision_0      F1_0  Recall_1  Precision_1      F1_1\n",
      "0           XGBoost + FE (tuned, Block 19)       NaN       NaN          NaN       NaN       NaN          NaN       NaN\n",
      "1  XGBoost + FE + Topics (tuned, Block 22)  0.852457  0.594633     0.637557  0.615347  0.916298     0.901273  0.908723\n"
     ]
    }
   ],
   "source": [
    "# Block 22 — XGBoost with engineered + topic features (+ tuned threshold)\n",
    "# Train XGBoost using contextual features plus NMF topic features and compare to previous XGB+FE.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- 1) Guard rails: check matrices with topics exist ---\n",
    "assert 'topic_1' in X_train_topics.columns, \"Topic features not found. Run Block 21 first.\"\n",
    "assert set(X_train_fe.index) == set(X_train_topics.index), \"Index mismatch between FE and topic matrices (train).\"\n",
    "assert set(X_test_fe.index)  == set(X_test_topics.index),  \"Index mismatch between FE and topic matrices (test).\"\n",
    "\n",
    "# --- 2) Define feature lists ---\n",
    "# Base contextual features (same as Block 18/19)\n",
    "base_num = ['EdadAtencion','min_registro_a_triage','hour','dow','is_weekend','month','arrivals_60m']\n",
    "cat_features = ['Genero']\n",
    "\n",
    "# Topic feature columns\n",
    "topic_cols = sorted([c for c in X_train_topics.columns if c.startswith('topic_')])\n",
    "\n",
    "# Final features: numeric includes base_num + topics; categorical keeps 'Genero'\n",
    "num_features = base_num + topic_cols\n",
    "\n",
    "# --- 3) Build train/test with topics (aligned indices) ---\n",
    "Xtr_topics = X_train_topics[cat_features + num_features].copy()\n",
    "Xte_topics = X_test_topics[cat_features + num_features].copy()\n",
    "ytr_topics = y_train_fe.copy()\n",
    "yte_topics = y_test_fe.copy()\n",
    "\n",
    "print(\"Shapes -> X_train_topics:\", Xtr_topics.shape, \" X_test_topics:\", Xte_topics.shape)\n",
    "\n",
    "# --- 4) Preprocessor: impute + scale numeric; impute + OHE categorical ---\n",
    "preprocessor_xgb_topics = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), num_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('ohe', OneHotEncoder(drop='if_binary', handle_unknown='ignore'))\n",
    "        ]), cat_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# --- 5) XGB model (no early stopping to avoid version issues) ---\n",
    "xgb_topics = XGBClassifier(\n",
    "    n_estimators=700,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    min_child_weight=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_topics_pipe = Pipeline(steps=[\n",
    "    ('prep', preprocessor_xgb_topics),\n",
    "    ('clf', xgb_topics)\n",
    "])\n",
    "\n",
    "# --- 6) Fit ---\n",
    "xgb_topics_pipe.fit(Xtr_topics, ytr_topics)\n",
    "\n",
    "# --- 7) Evaluate @ thr=0.5 ---\n",
    "proba_test = xgb_topics_pipe.predict_proba(Xte_topics)[:, 1]   # P(y=1: cumple ≤2h)\n",
    "y_pred_default = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "print(\"=== Confusion Matrix (XGB+FE+Topics, thr=0.5) ===\")\n",
    "print(confusion_matrix(yte_topics, y_pred_default))\n",
    "print(\"\\n=== Classification Report (XGB+FE+Topics, thr=0.5) ===\")\n",
    "print(classification_report(yte_topics, y_pred_default, digits=3))\n",
    "\n",
    "# --- 8) Tune threshold to maximize F1 for class 0 (no cumple ≤2h) ---\n",
    "proba_train = xgb_topics_pipe.predict_proba(Xtr_topics)[:, 1]\n",
    "p0_train = 1.0 - proba_train\n",
    "y0_train = (ytr_topics == 0).astype(int)\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y0_train, p0_train)\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    f1_0 = np.where((prec + rec) > 0, 2 * prec * rec / (prec + rec), 0.0)\n",
    "\n",
    "if thr.size > 0 and f1_0.size > 1:\n",
    "    f1_aligned = f1_0[1:]  # align with thresholds\n",
    "    best_idx = int(np.argmax(f1_aligned))\n",
    "    best_thr_for_class0 = thr[best_idx]\n",
    "else:\n",
    "    best_thr_for_class0 = 0.5\n",
    "\n",
    "print(f\"\\nBest threshold for class 0 (train): {best_thr_for_class0:.4f}\")\n",
    "\n",
    "# Apply tuned threshold on TEST\n",
    "p0_test = 1.0 - proba_test\n",
    "y_pred_tuned0 = (p0_test >= best_thr_for_class0).astype(int)  # 1 -> class 0\n",
    "y_pred_tuned = np.where(y_pred_tuned0 == 1, 0, 1)\n",
    "\n",
    "print(\"\\n=== Confusion Matrix (XGB+FE+Topics, tuned threshold) ===\")\n",
    "print(confusion_matrix(yte_topics, y_pred_tuned))\n",
    "print(\"\\n=== Classification Report (XGB+FE+Topics, tuned threshold) ===\")\n",
    "print(classification_report(yte_topics, y_pred_tuned, digits=3))\n",
    "\n",
    "# --- 9) Compact comparison vs XGB+FE (Block 19 tuned) ---\n",
    "def metrics_from_report(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    prec0 = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    rec0  = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    f1_0  = (2*prec0*rec0)/(prec0+rec0) if (prec0+rec0) > 0 else 0\n",
    "    prec1 = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    rec1  = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_1  = (2*prec1*rec1)/(prec1+rec1) if (prec1+rec1) > 0 else 0\n",
    "    acc   = (tn+tp)/(tn+fp+fn+tp)\n",
    "    return acc, rec0, prec0, f1_0, rec1, prec1, f1_1\n",
    "\n",
    "acc_tuned, rec0_tuned, prec0_tuned, f10_tuned, rec1_tuned, prec1_tuned, f11_tuned = metrics_from_report(yte_topics, y_pred_tuned)\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": \"XGBoost + FE (tuned, Block 19)\",\n",
    "        # Rellena aquí tus mejores métricas del Block 19 tuned si quieres fijarlas:\n",
    "        # (opcional) Si no las guardaste, puedes reimprimirlas desde Block 19.\n",
    "        \"Accuracy\": np.nan, \"Recall_0\": np.nan, \"Precision_0\": np.nan, \"F1_0\": np.nan,\n",
    "        \"Recall_1\": np.nan, \"Precision_1\": np.nan, \"F1_1\": np.nan\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"XGBoost + FE + Topics (tuned, Block 22)\",\n",
    "        \"Accuracy\": acc_tuned,\n",
    "        \"Recall_0\": rec0_tuned, \"Precision_0\": prec0_tuned, \"F1_0\": f10_tuned,\n",
    "        \"Recall_1\": rec1_tuned, \"Precision_1\": prec1_tuned, \"F1_1\": f11_tuned\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n=== Compact comparison (tuned) ===\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39fba43-d69d-4b39-b5ad-15275ef0e8a8",
   "metadata": {},
   "source": [
    "En este bloque se entrena un modelo de LightGBM utilizando las variables ingenierizadas y las características temáticas derivadas de MotivoConsulta. Se evalúa el desempeño con umbral estándar (0.5) y con un umbral ajustado para maximizar el F1 de la clase de incumplimiento (Triage III > 2 horas). Finalmente, se presenta una comparación compacta contra XGBoost con tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1da7e605-f4d3-426a-a886-009390dd8eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\wilmerbelza\\venv\\lib\\site-packages (from lightgbm) (2.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\wilmerbelza\\venv\\lib\\site-packages (from lightgbm) (1.16.1)\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 32.9 MB/s  0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "493650de-3dd1-4def-9efd-f92aacb5f223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20011, number of negative: 4948\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2966\n",
      "[LightGBM] [Info] Number of data points in the train set: 24959, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.801755 -> initscore=1.397299\n",
      "[LightGBM] [Info] Start training from score 1.397299\n",
      "=== Confusion Matrix (LGBM+FE+Topics, thr=0.5) ===\n",
      "[[ 986 1138]\n",
      " [ 391 8187]]\n",
      "\n",
      "=== Classification Report (LGBM+FE+Topics, thr=0.5) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.716     0.464     0.563      2124\n",
      "           1      0.878     0.954     0.915      8578\n",
      "\n",
      "    accuracy                          0.857     10702\n",
      "   macro avg      0.797     0.709     0.739     10702\n",
      "weighted avg      0.846     0.857     0.845     10702\n",
      "\n",
      "\n",
      "Best threshold for class 0 (train): 0.3967\n",
      "\n",
      "=== Confusion Matrix (LGBM+FE+Topics, tuned threshold) ===\n",
      "[[1252  872]\n",
      " [ 681 7897]]\n",
      "\n",
      "=== Classification Report (LGBM+FE+Topics, tuned threshold) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.648     0.589     0.617      2124\n",
      "           1      0.901     0.921     0.910      8578\n",
      "\n",
      "    accuracy                          0.855     10702\n",
      "   macro avg      0.774     0.755     0.764     10702\n",
      "weighted avg      0.850     0.855     0.852     10702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Block 23 — LightGBM with engineered + topic features (no warnings, no wrappers)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import set_config\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 1) Hacer que todas las transformaciones devuelvan DataFrame con nombres\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# 2) Entradas\n",
    "assert isinstance(X_train_topics, pd.DataFrame) and isinstance(X_test_topics, pd.DataFrame)\n",
    "ytr = y_train_fe.astype(int).copy()\n",
    "yte = y_test_fe.astype(int).copy()\n",
    "\n",
    "cat_features = ['Genero']\n",
    "base_num = ['EdadAtencion','min_registro_a_triage','hour','dow','is_weekend','month','arrivals_60m']\n",
    "topic_cols = sorted([c for c in X_train_topics.columns if c.startswith('topic_')])\n",
    "num_features = base_num + topic_cols\n",
    "\n",
    "Xtr = X_train_topics[cat_features + num_features].copy()\n",
    "Xte = X_test_topics[cat_features + num_features].copy()\n",
    "\n",
    "# 3) Preprocesado (ahora sklearn devolverá DataFrame automáticamente)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), num_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            # OHE en denso para que mantenga columnas en DataFrame\n",
    "            ('ohe', OneHotEncoder(drop='if_binary', handle_unknown='ignore', sparse_output=False))\n",
    "        ]), cat_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# 4) Modelo\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=700,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('prep', preprocessor),\n",
    "    ('clf', lgbm)\n",
    "])\n",
    "\n",
    "# 5) Entrenar\n",
    "pipe.fit(Xtr, ytr)\n",
    "\n",
    "# 6) Evaluar (thr=0.5)\n",
    "proba_test = pipe.predict_proba(Xte)[:, 1]   # sigue siendo DataFrame internamente; sin warnings\n",
    "y_pred = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "print(\"=== Confusion Matrix (LGBM+FE+Topics, thr=0.5) ===\")\n",
    "print(confusion_matrix(yte, y_pred))\n",
    "print(\"\\n=== Classification Report (LGBM+FE+Topics, thr=0.5) ===\")\n",
    "print(classification_report(yte, y_pred, digits=3))\n",
    "\n",
    "# 7) Ajuste de umbral para maximizar F1 de clase 0\n",
    "proba_train = pipe.predict_proba(Xtr)[:, 1]\n",
    "p0_train = 1.0 - proba_train\n",
    "y0_train = (ytr == 0).astype(int)\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y0_train, p0_train)\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    f1_0 = np.where((prec + rec) > 0, 2 * prec * rec / (prec + rec), 0.0)\n",
    "best_thr = thr[np.argmax(f1_0[1:])] if thr.size > 0 and f1_0.size > 1 else 0.5\n",
    "print(f\"\\nBest threshold for class 0 (train): {best_thr:.4f}\")\n",
    "\n",
    "p0_test = 1.0 - proba_test\n",
    "y_pred_tuned0 = (p0_test >= best_thr).astype(int)\n",
    "y_pred_tuned = np.where(y_pred_tuned0 == 1, 0, 1)\n",
    "\n",
    "print(\"\\n=== Confusion Matrix (LGBM+FE+Topics, tuned threshold) ===\")\n",
    "print(confusion_matrix(yte, y_pred_tuned))\n",
    "print(\"\\n=== Classification Report (LGBM+FE+Topics, tuned threshold) ===\")\n",
    "print(classification_report(yte, y_pred_tuned, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c2c7af-8d27-456f-b9c9-964e34fb4251",
   "metadata": {},
   "source": [
    "En este bloque se construye una tabla comparativa de desempeño entre los diferentes modelos evaluados (Random Forest, XGBoost y LightGBM). Para cada uno se reportan las métricas principales en su umbral ajustado, de modo que se visualicen las fortalezas relativas en precisión, recall y F1 para la clase de incumplimiento (Triage III > 2 horas) y la clase de cumplimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9cfb3b13-b6dd-42c9-8dc3-b50b44a09189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Model Comparison ===\n",
      "                                      Model  Accuracy  Recall_0  Precision_0   F1_0  Recall_1  Precision_1   F1_1\n",
      "0      Random Forest + FE (tuned, Block 19)     0.801     0.695        0.500  0.581     0.828        0.916  0.870\n",
      "1   XGBoost + FE + Topics (tuned, Block 22)     0.852     0.595        0.638  0.615     0.916        0.901  0.909\n",
      "2  LightGBM + FE + Topics (tuned, Block 23)     0.855     0.589        0.648  0.617     0.921        0.901  0.910\n"
     ]
    }
   ],
   "source": [
    "# Block 24 — Comparative performance table\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Resultados ya observados en bloques anteriores (rellenados a mano desde tus salidas)\n",
    "# Nota: puedes ajustar estos valores si vuelves a correr con nuevos umbrales\n",
    "results = [\n",
    "    {\n",
    "        \"Model\": \"Random Forest + FE (tuned, Block 19)\",\n",
    "        \"Accuracy\": 0.801,\n",
    "        \"Recall_0\": 0.695,\n",
    "        \"Precision_0\": 0.500,\n",
    "        \"F1_0\": 0.581,\n",
    "        \"Recall_1\": 0.828,\n",
    "        \"Precision_1\": 0.916,\n",
    "        \"F1_1\": 0.870\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"XGBoost + FE + Topics (tuned, Block 22)\",\n",
    "        \"Accuracy\": 0.852,\n",
    "        \"Recall_0\": 0.595,\n",
    "        \"Precision_0\": 0.638,\n",
    "        \"F1_0\": 0.615,\n",
    "        \"Recall_1\": 0.916,\n",
    "        \"Precision_1\": 0.901,\n",
    "        \"F1_1\": 0.909\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"LightGBM + FE + Topics (tuned, Block 23)\",\n",
    "        \"Accuracy\": 0.855,\n",
    "        \"Recall_0\": 0.589,\n",
    "        \"Precision_0\": 0.648,\n",
    "        \"F1_0\": 0.617,\n",
    "        \"Recall_1\": 0.921,\n",
    "        \"Precision_1\": 0.901,\n",
    "        \"F1_1\": 0.910\n",
    "    }\n",
    "]\n",
    "\n",
    "df_comparison = pd.DataFrame(results)\n",
    "print(\"=== Final Model Comparison ===\")\n",
    "print(df_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e2e19-ccae-4cee-afb3-670de2c59f0c",
   "metadata": {},
   "source": [
    "En este bloque se persisten los artefactos necesarios para inferencia en producción: (i) el pipeline completo de LightGBM con su preprocesamiento tabular, (ii) el umbral operativo seleccionado para la clase de incumplimiento, y (iii) los vectorizadores de texto (TF-IDF y NMF) utilizados para generar las variables temáticas a partir de MotivoConsulta. Adicionalmente, se guarda un archivo de metadatos con la versión del pipeline, las columnas esperadas y un ejemplo de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5dc69ed4-5f4e-421a-96ec-605cf9aed3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifacts:\n",
      " - Pipeline: C:\\Users\\wilmerbelza\\Documents\\Prediction model\\artifacts\\lgbm_topics_pipeline.pkl\n",
      " - TF-IDF  : C:\\Users\\wilmerbelza\\Documents\\Prediction model\\artifacts\\tfidf_vectorizer.pkl\n",
      " - NMF     : C:\\Users\\wilmerbelza\\Documents\\Prediction model\\artifacts\\nmf_model.pkl\n",
      " - Metadata: C:\\Users\\wilmerbelza\\Documents\\Prediction model\\artifacts\\model_metadata.json\n",
      "\n",
      "Smoke test — proba(class1) on 5 samples: [0.99471273 0.99367893 0.48729575 0.85319557 0.64802657]\n"
     ]
    }
   ],
   "source": [
    "# Block 25 — Persist artifacts for production (model, threshold, TF-IDF, NMF, metadata)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ====== 0) Preconditions ======\n",
    "# Assumes you already ran:\n",
    "# - Block 21 (created `tfidf`, `nmf`, and topic features)\n",
    "# - Block 23 (trained LightGBM pipeline `pipe` and tuned threshold `best_thr`)\n",
    "# - You have X_train_topics / X_test_topics and y_train_fe / y_test_fe\n",
    "assert 'pipe' in globals(), \"Missing `pipe` (trained LightGBM pipeline). Run Block 23.\"\n",
    "assert 'best_thr' in globals(), \"Missing `best_thr` (chosen operating threshold). Run Block 23.\"\n",
    "assert 'tfidf' in globals() and 'nmf' in globals(), \"Missing TF-IDF / NMF artifacts. Run Block 21.\"\n",
    "\n",
    "# ====== 1) Output directory & filenames ======\n",
    "SAVE_DIR = r\"C:\\Users\\wilmerbelza\\Documents\\Prediction model\\artifacts\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "FN_PIPELINE = os.path.join(SAVE_DIR, \"lgbm_topics_pipeline.pkl\")\n",
    "FN_TFIDF    = os.path.join(SAVE_DIR, \"tfidf_vectorizer.pkl\")\n",
    "FN_NMF      = os.path.join(SAVE_DIR, \"nmf_model.pkl\")\n",
    "FN_META     = os.path.join(SAVE_DIR, \"model_metadata.json\")\n",
    "\n",
    "# ====== 2) Collect schema & metadata ======\n",
    "# Expected columns (order matters for convenience)\n",
    "cat_features = ['Genero']\n",
    "base_num = ['EdadAtencion','min_registro_a_triage','hour','dow','is_weekend','month','arrivals_60m']\n",
    "topic_cols = sorted([c for c in X_train_topics.columns if c.startswith('topic_')])\n",
    "num_features = base_num + topic_cols\n",
    "expected_columns = cat_features + num_features\n",
    "\n",
    "metadata = {\n",
    "    \"model_name\": \"LightGBM + FE + Topics\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"operating_threshold_class0\": float(best_thr),  # threshold applied on P(class0) = 1 - proba(class1)\n",
    "    \"target_definition\": {\n",
    "        \"name\": \"target\",\n",
    "        \"description\": \"Triage III cumple ≤ 2h (1) vs no cumple > 2h (0), solo adultos y Triage III.\"\n",
    "    },\n",
    "    \"features\": {\n",
    "        \"categorical\": cat_features,\n",
    "        \"numeric\": num_features,\n",
    "        \"topic_features\": topic_cols\n",
    "    },\n",
    "    \"expects_columns_in_order\": expected_columns,\n",
    "    \"notes\": [\n",
    "        \"Pipeline (`pipe`) contains: ColumnTransformer(impute/scale/OHE) + LightGBM.\",\n",
    "        \"TF-IDF and NMF are stored separately to compute topic features from MotivoConsulta on new data.\",\n",
    "        \"Operating threshold is on class 0 (no cumplimiento), computed on train to maximize F1_0.\"\n",
    "    ],\n",
    "    \"example_inference\": {\n",
    "        \"steps\": [\n",
    "            \"1) Compute engineered features (hour, dow, is_weekend, month, arrivals_60m).\",\n",
    "            \"2) Transform MotivoConsulta -> TF-IDF -> NMF -> topic_1..topic_k with saved artifacts.\",\n",
    "            \"3) Build DataFrame with expected columns in order.\",\n",
    "            \"4) Call pipeline.predict_proba -> get P(class1).\",\n",
    "            \"5) Convert to class with tuned threshold on P(class0)=1-P(class1): class0 if p0>=thr else class1.\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ====== 3) Persist artifacts ======\n",
    "joblib.dump(pipe, FN_PIPELINE)\n",
    "joblib.dump(tfidf, FN_TFIDF)\n",
    "joblib.dump(nmf, FN_NMF)\n",
    "\n",
    "with open(FN_META, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved artifacts:\")\n",
    "print(\" - Pipeline:\", FN_PIPELINE)\n",
    "print(\" - TF-IDF  :\", FN_TFIDF)\n",
    "print(\" - NMF     :\", FN_NMF)\n",
    "print(\" - Metadata:\", FN_META)\n",
    "\n",
    "# ====== 4) Quick smoke test: reload and score few rows ======\n",
    "pipe_loaded = joblib.load(FN_PIPELINE)\n",
    "proba_sample = pipe_loaded.predict_proba(X_test_topics[expected_columns].head(5))[:, 1]\n",
    "print(\"\\nSmoke test — proba(class1) on 5 samples:\", proba_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d4238-b197-48d8-85df-b9ed2534a10d",
   "metadata": {},
   "source": [
    "En este bloque se ilustra cómo cargar los artefactos previamente guardados (pipeline de LightGBM, vectorizadores TF-IDF y NMF, y metadatos) para realizar predicciones en un entorno de producción. El procedimiento consiste en reconstruir las características esperadas, incluyendo las variables temáticas generadas a partir del campo MotivoConsulta, y aplicar el modelo con el umbral operativo afinado para distinguir entre pacientes que cumplen o no con el estándar de Triage III (≤2 horas). De esta manera, se asegura la reproducibilidad del pipeline y se habilita el uso del modelo en nuevos datos clínicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0900a4c-233b-4d3f-b773-45dd7defcb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 26 — Load artifacts and run inference with tuned operating threshold\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SAVE_DIR = r\"C:\\Users\\wilmerbelza\\Documents\\Prediction model\\artifacts\"\n",
    "FN_PIPELINE = os.path.join(SAVE_DIR, \"lgbm_topics_pipeline.pkl\")\n",
    "FN_TFIDF    = os.path.join(SAVE_DIR, \"tfidf_vectorizer.pkl\")\n",
    "FN_NMF      = os.path.join(SAVE_DIR, \"nmf_model.pkl\")\n",
    "FN_META     = os.path.join(SAVE_DIR, \"model_metadata.json\")\n",
    "\n",
    "# 1) Load artifacts\n",
    "pipe = joblib.load(FN_PIPELINE)\n",
    "tfidf = joblib.load(FN_TFIDF)\n",
    "nmf = joblib.load(FN_NMF)\n",
    "meta = json.load(open(FN_META, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "expected_cols = meta[\"expects_columns_in_order\"]\n",
    "thr = meta[\"operating_threshold_class0\"]\n",
    "\n",
    "# 2) Suppose you have a new batch with columns:\n",
    "# ['Genero','EdadAtencion','min_registro_a_triage','hour','dow','is_weekend','month','arrivals_60m','MotivoConsulta']\n",
    "# You must transform `MotivoConsulta` to topic_i using the saved tfidf+nmf, then assemble the matrix.\n",
    "\n",
    "def texts_to_topics(motivos: pd.Series, tfidf, nmf, n_topics: int) -> pd.DataFrame:\n",
    "    \"\"\"Convert MotivoConsulta series into topic features using saved TF-IDF and NMF.\"\"\"\n",
    "    X_tfidf = tfidf.transform(motivos.fillna(\"\").astype(str))\n",
    "    W = nmf.transform(X_tfidf)\n",
    "    cols = [f\"topic_{i+1}\" for i in range(n_topics)]\n",
    "    return pd.DataFrame(W, index=motivos.index, columns=cols)\n",
    "\n",
    "# Example: new_df contains raw engineered + text\n",
    "# new_df = pd.DataFrame({...})\n",
    "# topics = texts_to_topics(new_df['MotivoConsulta'], tfidf, nmf, n_topics=len([c for c in expected_cols if c.startswith('topic_')]))\n",
    "# X_new = pd.concat([new_df.drop(columns=['MotivoConsulta']), topics], axis=1)\n",
    "# X_new = X_new[expected_cols]  # ensure column order\n",
    "\n",
    "def predict_with_operating_point(X_new: pd.DataFrame, pipeline, thr_class0: float) -> pd.DataFrame:\n",
    "    \"\"\"Return proba, class using tuned threshold on class0 (p0 = 1 - p1).\"\"\"\n",
    "    proba1 = pipeline.predict_proba(X_new)[:, 1]\n",
    "    p0 = 1.0 - proba1\n",
    "    yhat = (p0 >= thr_class0).astype(int)    # 1->class0, 0->class1\n",
    "    yhat = np.where(yhat == 1, 0, 1)         # map back to {0:no cumple, 1:cumple}\n",
    "    out = pd.DataFrame({\n",
    "        \"proba_cumple_<=2h\": proba1,\n",
    "        \"proba_no_cumple\": p0,\n",
    "        \"pred_clase\": yhat\n",
    "    }, index=X_new.index)\n",
    "    return out\n",
    "\n",
    "# Example usage:\n",
    "# preds = predict_with_operating_point(X_new, pipe, thr)\n",
    "# print(preds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9db794-a092-4eac-8df8-18a31af65dc1",
   "metadata": {},
   "source": [
    "Este bloque recibe desde el Digital Twin (FlexSim) el tiempo entre Registro y Triage en formato hh:mm:ss y opcionalmente otras variables (edad, género, calendario y motivo de consulta).\n",
    "Convierte el tiempo a minutos, arma el registro con las columnas esperadas por el pipeline guardado en el Block 26 y realiza la predicción en línea: probabilidad de cumplir el estándar Triage III ≤ 2 horas y la clasificación usando el umbral operativo calibrado.\n",
    "Si no se proporciona MotivoConsulta pero el modelo espera tópicos, se rellenan con 0 (predicción válida pero menos precisa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99636ef3-b9ba-486c-bbbc-f7052b6263b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ingrese el tiempo Registro→Triage en formato hh:mm:ss:  00:49:55\n",
      "Edad del paciente:  33\n",
      "Género del paciente (Femenino/Masculino):  Masculino\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ONLINE PREDICTION (Triage III ≤ 2 horas) ===\n",
      "Input Digital Twin — Registro→Triage: 00:49:55  ->  49.92 min\n",
      "Edad: 33 | Género: Masculino\n",
      "Umbral operativo (class 0): 0.397\n",
      "Prob. CUMPLE ≤2h (clase 1): 0.951\n",
      "Predicción: CUMPLE (1)\n"
     ]
    }
   ],
   "source": [
    "# Block 27 — Online inference with interactive input (Registro→Triage in hh:mm:ss)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "# ---------- 1) Helper: hh:mm:ss → minutes ----------\n",
    "def hhmmss_to_minutes(hhmmss: str) -> float:\n",
    "    h, m, s = hhmmss.strip().split(\":\")\n",
    "    return int(h) * 60 + int(m) + int(s) / 60.0\n",
    "\n",
    "# ---------- 2) INPUTS FROM USER ----------\n",
    "tt_reg_tri_hhmmss = input(\"Ingrese el tiempo Registro→Triage en formato hh:mm:ss: \")\n",
    "edad_opt   = int(input(\"Edad del paciente: \"))\n",
    "genero_opt = input(\"Género del paciente (Femenino/Masculino): \")\n",
    "\n",
    "# ---------- 3) Load artifacts ----------\n",
    "SAVE_DIR   = r\"C:\\Users\\wilmerbelza\\Documents\\Prediction model\\artifacts\"\n",
    "FN_PIPE    = os.path.join(SAVE_DIR, \"lgbm_topics_pipeline.pkl\")\n",
    "FN_TFIDF   = os.path.join(SAVE_DIR, \"tfidf_vectorizer.pkl\")\n",
    "FN_NMF     = os.path.join(SAVE_DIR, \"nmf_model.pkl\")\n",
    "FN_META    = os.path.join(SAVE_DIR, \"model_metadata.json\")\n",
    "\n",
    "pipe  = joblib.load(FN_PIPE)\n",
    "tfidf = joblib.load(FN_TFIDF)\n",
    "nmf   = joblib.load(FN_NMF)\n",
    "with open(FN_META, \"r\", encoding=\"utf-8\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "expected_cols = meta.get(\"expects_columns_in_order\", [])\n",
    "thr_class0    = float(meta.get(\"operating_threshold_class0\", 0.5))\n",
    "\n",
    "# ---------- 4) Build base row ----------\n",
    "min_registro_a_triage_val = hhmmss_to_minutes(tt_reg_tri_hhmmss)\n",
    "base_row = {\n",
    "    'Genero': genero_opt,\n",
    "    'EdadAtencion': edad_opt,\n",
    "    'min_registro_a_triage': min_registro_a_triage_val,\n",
    "}\n",
    "X_new = pd.DataFrame([base_row])\n",
    "\n",
    "# Añadir columnas faltantes (relleno con 0 o NaN)\n",
    "for c in expected_cols:\n",
    "    if c not in X_new.columns:\n",
    "        X_new[c] = 0.0 if c.startswith(\"topic_\") else np.nan\n",
    "X_new = X_new[expected_cols]\n",
    "\n",
    "# ---------- 5) Fix dtypes ----------\n",
    "if 'Genero' in X_new.columns:\n",
    "    X_new['Genero'] = X_new['Genero'].astype('category')\n",
    "\n",
    "for c in X_new.columns:\n",
    "    if c != 'Genero':\n",
    "        X_new[c] = pd.to_numeric(X_new[c], errors='coerce')\n",
    "\n",
    "# ---------- 6) Predict ----------\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\n",
    "        \"ignore\",\n",
    "        message=\"X does not have valid feature names, but .* was fitted with feature names\"\n",
    "    )\n",
    "    warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "    proba1 = pipe.predict_proba(X_new)[:, 1]\n",
    "\n",
    "p0     = 1.0 - proba1\n",
    "yhat0  = (p0 >= thr_class0).astype(int)\n",
    "yhat   = np.where(yhat0 == 1, 0, 1)\n",
    "\n",
    "print(\"\\n=== ONLINE PREDICTION (Triage III ≤ 2 horas) ===\")\n",
    "print(f\"Input Digital Twin — Registro→Triage: {tt_reg_tri_hhmmss}  ->  {min_registro_a_triage_val:.2f} min\")\n",
    "print(f\"Edad: {edad_opt} | Género: {genero_opt}\")\n",
    "print(f\"Umbral operativo (class 0): {thr_class0:.3f}\")\n",
    "print(f\"Prob. CUMPLE ≤2h (clase 1): {proba1[0]:.3f}\")\n",
    "print(f\"Predicción: {'CUMPLE (1)' if yhat[0]==1 else 'NO CUMPLE (0)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de13ca7-61b1-4f13-a89f-009f59ffe335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
